{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"aimz: Scalable probabilistic impact modeling","text":""},{"location":"#overview","title":"Overview","text":"<p>aimz is a Python library for flexible and scalable probabilistic impact modeling to assess the effects of interventions on outcomes of interest. Designed to work with user-defined models with probabilistic primitives, the library builds on NumPyro, JAX, Xarray, and Zarr to enable efficient inference workflows.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>An intuitive API that combines ease of use from ML frameworks with the flexibility of probabilistic modeling.</li> <li>Scalable computation via parallelism and distributed data processing\u2014no manual orchestration required.</li> <li>Variational inference as the primary inference engine, supporting custom optimization strategies and results.</li> <li>Support for interventional causal inference for modeling counterfactuals and causal relations.</li> </ul>"},{"location":"#workflow","title":"Workflow","text":"<ol> <li>Outline the model, considering the data generating process, latent variables, and causal relationships, if any.</li> <li>Translate the model into a kernel (i.e., a function) using NumPyro and JAX.</li> <li>Integrate the kernel into the provided API to train the model and perform inference.</li> </ol>"},{"location":"array_dataset/","title":"ArrayDataset","text":"<p>ArrayDataset class for JAX arrays.</p> Source code in <code>aimz/utils/data/array_dataset.py</code> <pre><code>class ArrayDataset:\n    \"\"\"ArrayDataset class for JAX arrays.\"\"\"\n\n    def __init__(self, *, to_jax: bool = True, **arrays: ArrayLike | None) -&gt; None:\n        \"\"\"Initialize an ArrayDataset instance.\n\n        Args:\n            to_jax (bool): Whether to convert the input arrays to JAX arrays. Defaults\n                to `True`.\n            **arrays (ArrayLike): One or more JAX arrays or compatible array-like\n                objects.\n\n        Raises:\n            ValueError: If no arrays are provided or if the arrays do not have the same\n                length.\n        \"\"\"\n        arrays = {k: v for k, v in arrays.items() if v is not None}\n        if not arrays:\n            msg = \"At least one array must be provided.\"\n            raise ValueError(msg)\n        lengths = {len(arr) for arr in arrays.values()}\n        if len(lengths) != 1:\n            msg = \"All arrays must have the same length.\"\n            raise ValueError(msg)\n        (self.length,) = lengths\n        if to_jax:\n            self.arrays = {k: jnp.asarray(v) for k, v in arrays.items()}\n        else:\n            self.arrays = arrays\n\n    def __len__(self) -&gt; int:\n        \"\"\"Get the number of samples in the dataset.\n\n        Returns:\n            The number of samples.\n        \"\"\"\n        return self.length\n\n    def __getitem__(self, idx: int) -&gt; dict[str, Array]:\n        \"\"\"Retrieve the elements at the specified index.\n\n        Args:\n            idx: Index of the item to retrieve.\n\n        Returns:\n            A tuple containing the elements from each array at the specified index.\n        \"\"\"\n        return {k: v[idx] for k, v in self.arrays.items()}\n</code></pre>"},{"location":"array_dataset/#aimz.utils.data.array_dataset.ArrayDataset.__init__","title":"__init__","text":"<pre><code>__init__(*, to_jax: bool = True, **arrays: ArrayLike | None) -&gt; None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>to_jax</code> <code>bool</code> <p>Whether to convert the input arrays to JAX arrays. Defaults to <code>True</code>.</p> <code>True</code> <code>**arrays</code> <code>ArrayLike</code> <p>One or more JAX arrays or compatible array-like objects.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no arrays are provided or if the arrays do not have the same length.</p> Source code in <code>aimz/utils/data/array_dataset.py</code> <pre><code>def __init__(self, *, to_jax: bool = True, **arrays: ArrayLike | None) -&gt; None:\n    \"\"\"Initialize an ArrayDataset instance.\n\n    Args:\n        to_jax (bool): Whether to convert the input arrays to JAX arrays. Defaults\n            to `True`.\n        **arrays (ArrayLike): One or more JAX arrays or compatible array-like\n            objects.\n\n    Raises:\n        ValueError: If no arrays are provided or if the arrays do not have the same\n            length.\n    \"\"\"\n    arrays = {k: v for k, v in arrays.items() if v is not None}\n    if not arrays:\n        msg = \"At least one array must be provided.\"\n        raise ValueError(msg)\n    lengths = {len(arr) for arr in arrays.values()}\n    if len(lengths) != 1:\n        msg = \"All arrays must have the same length.\"\n        raise ValueError(msg)\n    (self.length,) = lengths\n    if to_jax:\n        self.arrays = {k: jnp.asarray(v) for k, v in arrays.items()}\n    else:\n        self.arrays = arrays\n</code></pre>"},{"location":"array_dataset/#aimz.utils.data.array_dataset.ArrayDataset.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Get the number of samples in the dataset.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of samples.</p> Source code in <code>aimz/utils/data/array_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Get the number of samples in the dataset.\n\n    Returns:\n        The number of samples.\n    \"\"\"\n    return self.length\n</code></pre>"},{"location":"array_dataset/#aimz.utils.data.array_dataset.ArrayDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx: int) -&gt; dict[str, Array]\n</code></pre> <p>Retrieve the elements at the specified index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>dict[str, Array]</code> <p>A tuple containing the elements from each array at the specified index.</p> Source code in <code>aimz/utils/data/array_dataset.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; dict[str, Array]:\n    \"\"\"Retrieve the elements at the specified index.\n\n    Args:\n        idx: Index of the item to retrieve.\n\n    Returns:\n        A tuple containing the elements from each array at the specified index.\n    \"\"\"\n    return {k: v[idx] for k, v in self.arrays.items()}\n</code></pre>"},{"location":"array_loader/","title":"ArrayLoader","text":"<p>ArrayLoader class for JAX arrays.</p> Source code in <code>aimz/utils/data/array_loader.py</code> <pre><code>class ArrayLoader:\n    \"\"\"ArrayLoader class for JAX arrays.\"\"\"\n\n    def __init__(\n        self,\n        dataset: ArrayDataset,\n        rng_key: Array,\n        *,\n        batch_size: int = 32,\n        shuffle: bool = False,\n        device: \"Sharding | None\" = None,\n    ) -&gt; None:\n        \"\"\"Initialize an ArrayLoader instance.\n\n        Args:\n            dataset (ArrayDataset): The dataset to load.\n            rng_key (Array): A pseudo-random number generator key.\n            batch_size (int): The number of samples per batch.\n            shuffle (bool, optional): Whether to shuffle the dataset before batching.\n            device (Sharding | None, optional): The device or sharding specification to\n                which the data should be moved. By default, no device transfer is\n                applied. When used as an input to a model, this will be overridden by\n                the device setting of the model.\n        \"\"\"\n        self.dataset = dataset\n        if (\n            not isinstance(batch_size, int)\n            or isinstance(batch_size, bool)\n            or batch_size &lt;= 0\n        ):\n            msg = f\"`batch_size` should be a positive integer, but got {batch_size!r}.\"\n            raise ValueError(msg)\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indices = jnp.arange(len(self.dataset))\n        if rng_key.dtype == jnp.uint32:\n            msg = \"Legacy `uint32` PRNGKey detected; converting to a typed key array.\"\n            warn(msg, category=UserWarning, stacklevel=2)\n            rng_key = random.wrap_key_data(rng_key)\n        self.rng_key = rng_key\n        self._num_devices = local_device_count()\n        self.device = device\n\n    def pad_array(self, x: \"Array | ndarray\", n_pad: int, axis: int = 0) -&gt; Array:\n        \"\"\"Pad an array to ensure compatibility with sharding.\n\n        Args:\n            x (Array | ndarray): The input array to be padded.\n            n_pad (int): The number of padding elements to add.\n            axis (int): The axis along which to apply the padding.\n\n        Returns:\n            The padded array with padding applied along the specified axis.\n\n        Raises:\n            ValueError: If padding is requested along an unsupported axis for a 1D\n                array.\n        \"\"\"\n        if x.ndim == 1:\n            if axis == 0:\n                return jnp.pad(x, pad_width=(0, n_pad), mode=\"edge\")\n            msg = \"Padding 1D arrays is only supported along axis 0.\"\n            raise ValueError(msg)\n\n        # Initialize all axes with no padding\n        pad_width: list[tuple[int, int]] = [(0, 0)] * x.ndim\n        # Apply padding to the specified axis\n        pad_width[axis] = (0, n_pad)\n\n        return jnp.pad(x, pad_width=pad_width, mode=\"edge\")\n\n    def __iter__(self) -&gt; Iterator[tuple[dict[str, Array], int]]:\n        \"\"\"Iterate over the dataset in batches.\n\n        Yields:\n            A batch of arrays with data from the dataset.\n            The number of padded samples added for sharding compatibility.\n        \"\"\"\n        indices = self.indices\n        if self.shuffle:\n            self.rng_key, subkey = random.split(self.rng_key)\n            indices = random.permutation(subkey, self.indices)\n        for start in range(0, len(self.dataset), self.batch_size):\n            end = start + self.batch_size\n            batch_idx = indices[start:end]\n            if self.device is not None:\n                n_pad = (-len(batch_idx)) % self._num_devices\n                batch = {\n                    k: self.pad_array(arr[batch_idx], n_pad=n_pad)\n                    for k, arr in self.dataset.arrays.items()\n                }\n                batch = {k: device_put(v, self.device) for k, v in batch.items()}\n            else:\n                n_pad = 0\n                batch = {k: arr[batch_idx] for k, arr in self.dataset.arrays.items()}\n            yield batch, n_pad\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of batches.\n\n        Returns:\n            The total number of batches.\n        \"\"\"\n        return ceil(len(self.dataset) / self.batch_size)\n</code></pre>"},{"location":"array_loader/#aimz.utils.data.array_loader.ArrayLoader.__init__","title":"__init__","text":"<pre><code>__init__(dataset: ArrayDataset, rng_key: Array, *, batch_size: int = 32, shuffle: bool = False, device: Sharding | None = None) -&gt; None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ArrayDataset</code> <p>The dataset to load.</p> required <code>rng_key</code> <code>Array</code> <p>A pseudo-random number generator key.</p> required <code>batch_size</code> <code>int</code> <p>The number of samples per batch.</p> <code>32</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the dataset before batching.</p> <code>False</code> <code>device</code> <code>Sharding | None</code> <p>The device or sharding specification to which the data should be moved. By default, no device transfer is applied. When used as an input to a model, this will be overridden by the device setting of the model.</p> <code>None</code> Source code in <code>aimz/utils/data/array_loader.py</code> <pre><code>def __init__(\n    self,\n    dataset: ArrayDataset,\n    rng_key: Array,\n    *,\n    batch_size: int = 32,\n    shuffle: bool = False,\n    device: \"Sharding | None\" = None,\n) -&gt; None:\n    \"\"\"Initialize an ArrayLoader instance.\n\n    Args:\n        dataset (ArrayDataset): The dataset to load.\n        rng_key (Array): A pseudo-random number generator key.\n        batch_size (int): The number of samples per batch.\n        shuffle (bool, optional): Whether to shuffle the dataset before batching.\n        device (Sharding | None, optional): The device or sharding specification to\n            which the data should be moved. By default, no device transfer is\n            applied. When used as an input to a model, this will be overridden by\n            the device setting of the model.\n    \"\"\"\n    self.dataset = dataset\n    if (\n        not isinstance(batch_size, int)\n        or isinstance(batch_size, bool)\n        or batch_size &lt;= 0\n    ):\n        msg = f\"`batch_size` should be a positive integer, but got {batch_size!r}.\"\n        raise ValueError(msg)\n    self.batch_size = batch_size\n    self.shuffle = shuffle\n    self.indices = jnp.arange(len(self.dataset))\n    if rng_key.dtype == jnp.uint32:\n        msg = \"Legacy `uint32` PRNGKey detected; converting to a typed key array.\"\n        warn(msg, category=UserWarning, stacklevel=2)\n        rng_key = random.wrap_key_data(rng_key)\n    self.rng_key = rng_key\n    self._num_devices = local_device_count()\n    self.device = device\n</code></pre>"},{"location":"array_loader/#aimz.utils.data.array_loader.ArrayLoader.pad_array","title":"pad_array","text":"<pre><code>pad_array(x: Array | ndarray, n_pad: int, axis: int = 0) -&gt; Array\n</code></pre> <p>Pad an array to ensure compatibility with sharding.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Array | ndarray</code> <p>The input array to be padded.</p> required <code>n_pad</code> <code>int</code> <p>The number of padding elements to add.</p> required <code>axis</code> <code>int</code> <p>The axis along which to apply the padding.</p> <code>0</code> <p>Returns:</p> Type Description <code>Array</code> <p>The padded array with padding applied along the specified axis.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If padding is requested along an unsupported axis for a 1D array.</p> Source code in <code>aimz/utils/data/array_loader.py</code> <pre><code>def pad_array(self, x: \"Array | ndarray\", n_pad: int, axis: int = 0) -&gt; Array:\n    \"\"\"Pad an array to ensure compatibility with sharding.\n\n    Args:\n        x (Array | ndarray): The input array to be padded.\n        n_pad (int): The number of padding elements to add.\n        axis (int): The axis along which to apply the padding.\n\n    Returns:\n        The padded array with padding applied along the specified axis.\n\n    Raises:\n        ValueError: If padding is requested along an unsupported axis for a 1D\n            array.\n    \"\"\"\n    if x.ndim == 1:\n        if axis == 0:\n            return jnp.pad(x, pad_width=(0, n_pad), mode=\"edge\")\n        msg = \"Padding 1D arrays is only supported along axis 0.\"\n        raise ValueError(msg)\n\n    # Initialize all axes with no padding\n    pad_width: list[tuple[int, int]] = [(0, 0)] * x.ndim\n    # Apply padding to the specified axis\n    pad_width[axis] = (0, n_pad)\n\n    return jnp.pad(x, pad_width=pad_width, mode=\"edge\")\n</code></pre>"},{"location":"array_loader/#aimz.utils.data.array_loader.ArrayLoader.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Iterator[tuple[dict[str, Array], int]]\n</code></pre> <p>Iterate over the dataset in batches.</p> <p>Yields:</p> Type Description <code>dict[str, Array]</code> <p>A batch of arrays with data from the dataset.</p> <code>int</code> <p>The number of padded samples added for sharding compatibility.</p> Source code in <code>aimz/utils/data/array_loader.py</code> <pre><code>def __iter__(self) -&gt; Iterator[tuple[dict[str, Array], int]]:\n    \"\"\"Iterate over the dataset in batches.\n\n    Yields:\n        A batch of arrays with data from the dataset.\n        The number of padded samples added for sharding compatibility.\n    \"\"\"\n    indices = self.indices\n    if self.shuffle:\n        self.rng_key, subkey = random.split(self.rng_key)\n        indices = random.permutation(subkey, self.indices)\n    for start in range(0, len(self.dataset), self.batch_size):\n        end = start + self.batch_size\n        batch_idx = indices[start:end]\n        if self.device is not None:\n            n_pad = (-len(batch_idx)) % self._num_devices\n            batch = {\n                k: self.pad_array(arr[batch_idx], n_pad=n_pad)\n                for k, arr in self.dataset.arrays.items()\n            }\n            batch = {k: device_put(v, self.device) for k, v in batch.items()}\n        else:\n            n_pad = 0\n            batch = {k: arr[batch_idx] for k, arr in self.dataset.arrays.items()}\n        yield batch, n_pad\n</code></pre>"},{"location":"array_loader/#aimz.utils.data.array_loader.ArrayLoader.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the number of batches.</p> <p>Returns:</p> Type Description <code>int</code> <p>The total number of batches.</p> Source code in <code>aimz/utils/data/array_loader.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of batches.\n\n    Returns:\n        The total number of batches.\n    \"\"\"\n    return ceil(len(self.dataset) / self.batch_size)\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Added a <code>return_sites</code> parameter to the <code>.predict()</code> and <code>.predict_on_batch()</code> methods in <code>ImpactModel</code>, allowing users to specify which sites to include in the output (@markean, #55).</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fixed incompatibility with Zarr when models output arrays in <code>bfloat16</code> by automatically promoting them to <code>float32</code> before saving (@markean, #57).</li> </ul>"},{"location":"changelog/#v040-2025-08-18","title":"v0.4.0 - 2025-08-18","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Support for NumPyro MCMC in <code>ImpactModel</code>, including <code>.fit_on_batch()</code>, <code>.sample()</code>, and <code>.set_posterior_sample()</code> methods (@markean, #35).</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li><code>ImpactModel</code> methods <code>.predict()</code>, <code>.predict_on_batch()</code>, <code>.log_likelihood()</code>, and <code>.estimate_effect()</code> now return outputs as xarray DataTree instead of ArviZ InferenceData. Dimension names now follow the <code>dim_N</code> convention instead of the previous <code>dimN</code> style (@markean, #49).</li> <li><code>.fit()</code>, <code>.fit_on_batch()</code>, and <code>.train_on_batch()</code> methods in <code>ImpactModel</code> now check for <code>\"/\"</code> in kernel site names to ensure compatibility with xarray DataTree (@markean, #49).</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Removed the <code>arviz</code> dependency (@markean, #49).</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li><code>.predict()</code> in <code>ImpactModel</code> now checks for available posterior samples before falling back to <code>.predict_on_batch()</code>.</li> <li><code>ArrayLoader</code> validates that <code>batch_size</code> is a positive integer.</li> </ul>"},{"location":"changelog/#v032-2025-08-13","title":"v0.3.2 - 2025-08-13","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Updated <code>.predict()</code> and <code>.predict_on_batch()</code> to check for available posterior samples before returning outputs. This prevents errors when posterior samples are not defined based on the model specification.</li> </ul>"},{"location":"changelog/#v031-2025-08-02","title":"v0.3.1 - 2025-08-02","text":""},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li><code>ArrayDataset</code> and <code>ArrayLoader</code> now preserve the order in which input arrays are provided, ensuring consistent input mapping in methods like <code>.predict()</code> and <code>.log_likelihood()</code> (@markean, #43).</li> </ul>"},{"location":"changelog/#v030-2025-07-18","title":"v0.3.0 - 2025-07-18","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li><code>ImpactModel</code> initialization parameter <code>vi</code> has been renamed to <code>inference</code> for compatibility with MCMC in future releases (@markean, #36).</li> <li><code>ImpactModel</code> now supports <code>ArrayLoader</code> for both input and output data (@markean, #24).</li> <li>Renamed the posterior sample attribute of <code>ImpactModel</code> from <code>.posterior_samples_</code> to <code>.posterior</code>, which is now initialized to <code>None</code> (@markean, #25).</li> <li><code>ArrayLoader</code> and <code>ArrayDataset</code> no longer require the <code>torch</code> dependency. <code>ArrayDataset</code> now accepts only named arrays, and <code>ArrayLoader</code> yields tuples of a dictionary and a padding integer (@markean, #26).</li> </ul>"},{"location":"changelog/#removed_1","title":"Removed","text":"<ul> <li>Removed the <code>torch</code> dependency (@markean, #26).</li> </ul>"},{"location":"changelog/#v020-2025-07-10","title":"v0.2.0 - 2025-07-10","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li><code>.train_on_batch()</code> and <code>.fit_on_batch()</code> methods to <code>ImpactModel</code> (@markean, #15).</li> <li>Custom <code>ArrayDataset</code> class for handling data in <code>ImpactModel</code>, removing the need for the <code>jax-dataloader</code> dependency (@markean, #14).</li> <li>GitHub Pages documentation site (@markean, #10).</li> <li>Installation instructions in the documentation site (@markean, #10).</li> <li><code>ArrayLoader</code> class supports <code>shuffle</code> and <code>drop_last</code> parameters for epoch training for <code>.fit()</code> (@markean, #15).</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Adopted <code>jax.typing</code> module for improved type hints.</li> <li>Removed unnecessary JAX array type conversion in <code>ImpactModel</code> methods.</li> <li>The <code>.fit()</code> method now uses epoch-based (minibatch) training (@markean, #15).</li> <li>Updated <code>.fit()</code>, <code>.train_on_batch()</code>, and <code>.fit_on_batch()</code> to train the model using the internal SVI state, continuing from the last state if available (@markean, #15).</li> </ul>"},{"location":"changelog/#removed_2","title":"Removed","text":"<ul> <li>Removed the <code>jax-dataloader</code> dependency (@markean, #14).</li> <li>Removed the <code>guide</code> property, as it is part of the <code>vi</code> property.</li> </ul>"},{"location":"changelog/#v010-2025-06-27","title":"v0.1.0 - 2025-06-27","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Initial public release.</li> </ul>"},{"location":"impact_model/","title":"ImpactModel","text":"<p>A class for impact modeling.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>class ImpactModel(BaseModel):\n    \"\"\"A class for impact modeling.\"\"\"\n\n    def __init__(\n        self,\n        kernel: Callable,\n        rng_key: Array,\n        inference: SVI | MCMC,\n        *,\n        param_input: str = \"X\",\n        param_output: str = \"y\",\n    ) -&gt; None:\n        \"\"\"Initialize an ImpactModel instance.\n\n        Args:\n            kernel (Callable): A probabilistic model with Pyro primitives.\n            rng_key (Array): A pseudo-random number generator key.\n            inference (SVI | MCMC): An inference method supported by NumPyro, such\n                as an instance of `numpyro.infer.svi.SVI` or `numpyro.infer.mcmc.MCMC`.\n            param_input (str, optional): The name of the parameter in the `kernel` for\n                the main input data.\n            param_output (str, optional): The name of the parameter in the `kernel` for\n                the output data.\n\n        Warning:\n            The `rng_key` parameter should be provided as a **typed key array**\n            created with `jax.random.key()`, rather than a legacy `uint32` key created\n            with `jax.random.PRNGKey()`.\n        \"\"\"\n        super().__init__(kernel, param_input, param_output)\n        if rng_key.dtype == jnp.uint32:\n            msg = \"Legacy `uint32` PRNGKey detected; converting to a typed key array.\"\n            warn(msg, category=UserWarning, stacklevel=2)\n            rng_key = random.wrap_key_data(rng_key)\n        self.rng_key = rng_key\n        if not isinstance(inference, (SVI, MCMC)):\n            msg = (\n                f\"Unsupported inference object: `{type(inference).__name__}`. \"\n                \"Expected `SVI` or `MCMC` from `numpyro.infer`.\"\n            )\n            raise TypeError(msg)\n        self.inference = inference\n        self._vi_state = None\n        self.posterior: dict[str, Array] | None = None\n        self._init_runtime_attrs()\n\n    def _init_runtime_attrs(self) -&gt; None:\n        \"\"\"Initialize runtime attributes.\"\"\"\n        self._fn_vi_update: Callable | None = None\n        self._fn_sample_posterior_predictive: Callable | None = None\n        self._fn_log_likelihood: Callable | None = None\n        self._mesh: Mesh | None\n        self._device: NamedSharding | None\n        num_devices = local_device_count()\n        if num_devices &gt; 1:\n            self._mesh = make_mesh((num_devices,), (\"obs\",))\n            self._device = NamedSharding(self._mesh, PartitionSpec(\"obs\"))\n        else:\n            self._mesh = None\n            self._device = None\n        logger.info(\n            \"Backend: %s, Devices: %d\",\n            default_backend(),\n            num_devices,\n        )\n\n    def __del__(self) -&gt; None:\n        \"\"\"Clean up the temporary directory when the instance is deleted.\"\"\"\n        self.cleanup()\n        # Call the parent's __del__ method only if it exists and is callable\n        super_del = getattr(super(), \"__del__\", None)\n        if callable(super_del):\n            super_del()\n\n    def __getstate__(self) -&gt; dict:\n        \"\"\"Return the state of the object excluding runtime attributes.\n\n        Returns:\n            The state of the object, excluding runtime attributes.\n        \"\"\"\n        return {\n            k: v\n            for k, v in self.__dict__.items()\n            if not (\n                k.startswith(\"_fn\")\n                or k in {\"_device\", \"_mesh\", \"_num_devices\", \"temp_dir\"}\n            )\n        }\n\n    def __setstate__(self, state: dict[str, object]) -&gt; None:\n        \"\"\"Restore the state and reinitialize runtime attributes.\n\n        Args:\n            state (dict): The state to restore, excluding the runtime attributes.\n        \"\"\"\n        self.__dict__.update(state)\n        self._init_runtime_attrs()\n\n    @property\n    def vi_result(self) -&gt; SVIRunResult:\n        \"\"\"Get the current variational inference result.\n\n        Returns:\n            The stored result from variational inference.\n        \"\"\"\n        return self._vi_result\n\n    @vi_result.setter\n    def vi_result(self, vi_result: SVIRunResult) -&gt; None:\n        \"\"\"Set the variational inference result manually.\n\n        This sets the result from a variational inference run and marks the model as\n        fitted. It does not perform posterior sampling \u2014 use `.sample()` separately to\n        obtain samples.\n\n        Args:\n            vi_result (SVIRunResult): The result from a prior variational inference run.\n                It must be a NamedTuple or similar object with the following fields:\n                - params (dict): Learned parameters from inference.\n                - state (SVIState): Internal SVI state object.\n                - losses (ArrayLike): Loss values recorded during optimization.\n        \"\"\"\n        if np.any(np.isnan(vi_result.losses)):\n            msg = \"Loss contains NaN or Inf, indicating numerical instability.\"\n            warn(msg, category=RuntimeWarning, stacklevel=2)\n\n        self._is_fitted = True\n\n        self._vi_result = vi_result\n\n    def sample_prior_predictive(\n        self,\n        X: ArrayLike,\n        *,\n        num_samples: int = 1000,\n        rng_key: Array | None = None,\n        return_sites: tuple[str] | None = None,\n        **kwargs: object,\n    ) -&gt; dict[str, Array]:\n        \"\"\"Draw samples from the prior predictive distribution.\n\n        Args:\n            X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n            num_samples (int, optional): The number of samples to draw.\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed.\n            return_sites (tuple[str] | None, optional): Names of variables (sites) to\n                return. If `None`, samples all latent, observed, and deterministic\n                sites.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            Prior predictive samples.\n\n        Raises:\n            TypeError: If `self.param_output` is passed as an argument.\n        \"\"\"\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n\n        # Validate the provided parameters against the kernel's signature\n        args_bound = (\n            signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n        )\n        if self.param_output in args_bound:\n            sub = self.param_output\n            msg = f\"{sub!r} is not allowed in `.sample_prior_predictive()`.\"\n            raise TypeError(msg)\n\n        return _sample_forward(\n            self.kernel,\n            rng_key=rng_key,\n            num_samples=num_samples,\n            return_sites=return_sites,\n            posterior_samples=None,\n            model_kwargs=args_bound,\n        )\n\n    def sample(\n        self,\n        num_samples: int = 1000,\n        rng_key: Array | None = None,\n        return_sites: tuple[str] | None = None,\n        **kwargs: object,\n    ) -&gt; dict[str, Array]:\n        \"\"\"Draw posterior samples from a fitted model.\n\n        Args:\n            num_samples (int, optional): The number of posterior samples to draw.\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed. Has no effect if\n                the inference method is MCMC, where the `post_warmup_state` property\n                will be used to continue sampling.\n            return_sites (tuple[str] | None, optional): Names of variables (sites) to\n                return. If `None`, samples all latent sites. Has no effect if the\n                inference method is MCMC.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays. Only relevant when the inference\n                method is MCMC.\n\n        Returns:\n            Posterior samples.\n\n        \"\"\"\n        _check_is_fitted(self)\n\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n\n        if isinstance(self.inference, MCMC):\n            # Validate the provided parameters against the kernel's signature\n            args_bound = signature(self.kernel).bind(**kwargs).arguments\n            if self.param_output not in args_bound:\n                msg = f\"{self.param_output!r} must be provided in `.sample()`.\"\n                raise TypeError(msg)\n            self.inference.post_warmup_state = self.inference.last_state\n            self.inference.num_samples = num_samples\n            self.inference.run(self.inference.post_warmup_state.rng_key, **args_bound)\n\n            return device_get(self.inference.get_samples())\n\n        return _sample_forward(\n            substitute(self.inference.guide, data=self.vi_result.params),\n            rng_key=rng_key,\n            num_samples=num_samples,\n            return_sites=return_sites,\n            posterior_samples=None,\n            model_kwargs=None,\n        )\n\n    def sample_posterior_predictive(\n        self,\n        X: ArrayLike,\n        *,\n        rng_key: Array | None = None,\n        return_sites: tuple[str] | None = None,\n        intervention: dict | None = None,\n        **kwargs: object,\n    ) -&gt; dict[str, Array]:\n        \"\"\"Draw samples from the posterior predictive distribution.\n\n        Args:\n            X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed.\n            return_sites (tuple[str] | None, optional): Names of variables (sites) to\n                return. If `None`, samples `self.param_output` and deterministic sites.\n            intervention (dict | None, optional): A dictionary mapping sample sites to\n                their corresponding intervention values. Interventions enable\n                counterfactual analysis by modifying the specified sample sites during\n                prediction (posterior predictive sampling).\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            Posterior predictive samples.\n\n        Raises:\n            TypeError: If `self.param_output` is passed as an argument.\n        \"\"\"\n        _check_is_fitted(self)\n\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n\n        X = jnp.asarray(check_array(X))\n\n        # Validate the provided parameters against the kernel's signature\n        args_bound = (\n            signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n        )\n        if self.param_output in args_bound:\n            sub = self.param_output\n            msg = f\"{sub!r} is not allowed in `.sample_prior_predictive()`.\"\n            raise TypeError(msg)\n\n        if intervention is None:\n            kernel = self.kernel\n        else:\n            rng_key, rng_subkey = random.split(rng_key)\n            kernel = seed(do(self.kernel, data=intervention), rng_seed=rng_subkey)\n\n        return _sample_forward(\n            kernel,\n            rng_key=rng_key,\n            num_samples=self.num_samples,\n            return_sites=return_sites or self._return_sites,\n            posterior_samples=self.posterior,\n            model_kwargs=args_bound,\n        )\n\n    def train_on_batch(\n        self,\n        X: ArrayLike,\n        y: ArrayLike,\n        rng_key: Array | None = None,\n        **kwargs: object,\n    ) -&gt; tuple[SVIState, Array]:\n        \"\"\"Run a single VI step on the given batch of data.\n\n        Args:\n            X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n            y (ArrayLike): Output data with shape `(n_samples_Y,)`.\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed. The key is only\n                used for initialization if the internal SVI state is not yet set.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            (SVIState): Updated SVI state after the training step.\n            (ArrayLike): Loss value as a scalar array.\n\n        Note:\n            This method updates the internal SVI state on every call, so it is not\n            necessary to capture the returned state externally unless explicitly needed.\n            However, the returned loss value can be used for monitoring or logging.\n        \"\"\"\n        batch = {self.param_input: X, self.param_output: y, **kwargs}\n\n        if self._vi_state is None:\n            # Validate the provided parameters against the kernel's signature\n            model_trace = trace(seed(self.kernel, rng_seed=self.rng_key)).get_trace(\n                **signature(self.kernel).bind(**batch).arguments,\n            )\n            # Validate the kernel body for output sample site and naming conflicts\n            _validate_kernel_body(\n                self.kernel,\n                self.param_output,\n                model_trace,\n            )\n            self._return_sites = (\n                *(\n                    k\n                    for k, site in model_trace.items()\n                    if site[\"type\"] == \"deterministic\"\n                ),\n                self.param_output,\n            )\n            if rng_key is None:\n                self.rng_key, rng_key = random.split(self.rng_key)\n            self._vi_state = self.inference.init(rng_key, **batch)\n        if self._fn_vi_update is None:\n            _, kwargs_extra = _group_kwargs(kwargs)\n            self._fn_vi_update = jit(\n                self.inference.update,\n                static_argnames=tuple(kwargs_extra._fields),\n            )\n\n        self._vi_state, loss = self._fn_vi_update(self._vi_state, **batch)\n\n        return self._vi_state, loss\n\n    def fit_on_batch(\n        self,\n        X: ArrayLike,\n        y: ArrayLike,\n        *,\n        num_steps: int = 10000,\n        num_samples: int = 1000,\n        rng_key: Array | None = None,\n        progress: bool = True,\n        **kwargs: object,\n    ) -&gt; Self:\n        \"\"\"Fit the impact model to the provided batch of data.\n\n        This method behaves differently depending on the inference method specified at\n        initialization of the ImpactModel instance:\n\n        - **SVI:** Runs variational inference on the provided batch by invoking the\n        `run()` method of the `SVI` instance from NumPyro to estimate the posterior\n        distribution, then draws samples from it.\n\n        - **MCMC:** Runs posterior sampling by invoking the `run()` method of the `MCMC`\n            instance from NumPyro.\n\n        Args:\n            X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n            y (ArrayLike): Output data with shape `(n_samples_Y,)`.\n            num_steps (int, optional): Number of steps for variational inference\n                optimization. Has no effect if the inference method is MCMC.\n            num_samples (int | None, optional): The number of posterior samples to draw.\n                Has no effect if the inference method is MCMC.\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed.\n            progress (bool, optional): Whether to display a progress bar. Has no effect\n                if the inference method is MCMC.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            The fitted model instance, enabling method chaining.\n\n        Note:\n            This method continues training from the existing SVI state if available. To\n            start training from scratch, create a new model instance.\n        \"\"\"\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n\n        X, y = map(jnp.asarray, check_X_y(X, y, force_writeable=True, y_numeric=True))\n\n        # Validate the provided parameters against the kernel's signature\n        args_bound = (\n            signature(self.kernel)\n            .bind(**{self.param_input: X, self.param_output: y, **kwargs})\n            .arguments\n        )\n        model_trace = trace(seed(self.kernel, rng_seed=self.rng_key)).get_trace(\n            **args_bound,\n        )\n        # Validate the kernel body for output sample site and naming conflicts\n        _validate_kernel_body(\n            self.kernel,\n            self.param_output,\n            model_trace,\n        )\n        self._return_sites = (\n            *(k for k, site in model_trace.items() if site[\"type\"] == \"deterministic\"),\n            self.param_output,\n        )\n\n        rng_key, rng_subkey = random.split(rng_key)\n        if isinstance(self.inference, SVI):\n            self.num_samples = num_samples\n            logger.info(\"Performing variational inference optimization...\")\n            self.vi_result = self.inference.run(\n                rng_subkey,\n                num_steps=num_steps,\n                progress_bar=progress,\n                init_state=self._vi_state,\n                **args_bound,\n            )\n            self._vi_state = self.vi_result.state\n            if np.any(np.isnan(self.vi_result.losses)):\n                warn(\n                    \"Loss contains NaN or Inf, indicating numerical instability.\",\n                    category=RuntimeWarning,\n                    stacklevel=2,\n                )\n            logger.info(\"Posterior sampling...\")\n            rng_key, rng_subkey = random.split(rng_key)\n            self.posterior = self.sample(self.num_samples, rng_key=rng_subkey)\n        elif isinstance(self.inference, MCMC):\n            logger.info(\"Posterior sampling...\")\n            self.inference.run(rng_subkey, **args_bound)\n            self.posterior = device_get(self.inference.get_samples())\n            self.num_samples = (\n                next(iter(self.posterior.values())).shape[0] if self.posterior else 0\n            )\n\n        self._is_fitted = True\n        self._dt_posterior = (\n            _dict_to_datatree(self.posterior) if self.posterior else None\n        )\n\n        return self\n\n    def fit(\n        self,\n        X: ArrayLike | ArrayLoader,\n        y: ArrayLike | None = None,\n        *,\n        num_samples: int = 1000,\n        rng_key: Array | None = None,\n        progress: bool = True,\n        batch_size: int | None = None,\n        epochs: int = 1,\n        shuffle: bool = True,\n        **kwargs: object,\n    ) -&gt; Self:\n        \"\"\"Fit the impact model to the provided data using epoch-based training.\n\n        This method implements an epoch-based training loop, where the data is iterated\n        over in minibatches for a specified number of epochs. Variational inference is\n        performed by repeatedly updating the model parameters on each minibatch, and\n        then posterior samples are drawn from the fitted model.\n\n        Args:\n            X (ArrayLike | ArrayLoader): Input data, either an array-like of shape\n                `(n_samples, n_features)` or a data loader that holds all array-like\n                objects and handles batching internally; if a data loader is passed,\n                `batch_size` is ignored.\n            y (ArrayLike | None): Output data with shape `(n_samples_Y,)`. Must be\n                `None` if `X` is a data loader.\n            num_samples (int | None, optional): The number of posterior samples to draw.\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed.\n            progress (bool, optional): Whether to display a progress bar.\n            batch_size (int | None, optional): The number of data points processed at\n                each step of variational inference. If `None` (default), the entire\n                dataset is used as a single batch in each epoch.\n            epochs (int, optional): The number of epochs for variational inference\n                optimization.\n            shuffle (bool, optional): Whether to shuffle the data at each epoch.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            The fitted model instance, enabling method chaining.\n\n        Raises:\n            TypeError: If the inference method is MCMC.\n\n        Note:\n            This method continues training from the existing SVI state if available.\n            To start training from scratch, create a new model instance. It does not\n            check whether the model or guide is written to support subsampling semantics\n            (e.g., using NumPyro's `subsample` or similar constructs).\n        \"\"\"\n        if isinstance(self.inference, MCMC):\n            msg = (\n                \"`.fit()` is not supported for MCMC inference. Use `.fit_on_batch()` \"\n                \"instead.\"\n            )\n            raise TypeError(msg)\n\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n\n        self.num_samples = num_samples\n\n        rng_key, rng_subkey = random.split(rng_key)\n        dataloader, kwargs_extra = _setup_inputs(\n            X=X,\n            y=y,\n            rng_key=rng_subkey,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            device=None,\n            **kwargs,\n        )\n\n        logger.info(\"Performing variational inference optimization...\")\n        losses: list[float] = []\n        rng_key, rng_subkey = random.split(rng_key)\n        for epoch in range(epochs):\n            losses_epoch: list[float] = []\n            pbar = tqdm(\n                dataloader,\n                total=len(dataloader),\n                desc=f\"Epoch {epoch + 1}/{epochs}\",\n                disable=not progress,\n            )\n            for batch, _ in pbar:\n                self._vi_state, loss = self.train_on_batch(\n                    **batch,\n                    **kwargs_extra._asdict(),\n                    rng_key=rng_subkey,\n                )\n                loss_batch = device_get(loss)\n                losses_epoch.append(loss_batch)\n                pbar.set_postfix({\"loss\": f\"{float(loss_batch):.4f}\"})\n            losses_epoch_arr = jnp.stack(losses_epoch)\n            losses.extend(losses_epoch_arr)\n            tqdm.write(\n                f\"Epoch {epoch + 1}/{epochs} - \"\n                f\"Average loss: {float(jnp.mean(losses_epoch_arr)):.4f}\",\n            )\n        self.vi_result = SVIRunResult(\n            params=self.inference.get_params(self._vi_state),\n            state=self._vi_state,\n            losses=jnp.asarray(losses),\n        )\n        if np.any(np.isnan(self.vi_result.losses)):\n            msg = \"Loss contains NaN or Inf, indicating numerical instability.\"\n            warn(msg, category=RuntimeWarning, stacklevel=2)\n\n        self._is_fitted = True\n\n        logger.info(\"Posterior sampling...\")\n        rng_key, rng_subkey = random.split(rng_key)\n        self.posterior = self.sample(self.num_samples, rng_key=rng_subkey)\n        self._dt_posterior = (\n            _dict_to_datatree(self.posterior) if self.posterior else None\n        )\n\n        return self\n\n    def is_fitted(self) -&gt; bool:\n        \"\"\"Check fitted status.\n\n        Returns:\n            `True` if the model is fitted, `False` otherwise.\n\n        \"\"\"\n        return hasattr(self, \"_is_fitted\") and self._is_fitted\n\n    def set_posterior_sample(\n        self,\n        posterior_sample: dict[str, Array],\n        return_sites: tuple[str] | None = None,\n    ) -&gt; Self:\n        \"\"\"Set posterior samples for the model.\n\n        This method sets externally obtained posterior samples on the model instance,\n        enabling downstream analysis without requiring a call to `.fit()` or\n        `.fit_on_batch()`.\n\n        It is primarily intended for workflows where posterior sampling is performed\n        manually\u2014for example, using NumPyro's `SVI` (or `MCMC`) with the `Predictive`\n        API\u2014and the resulting posterior samples are injected into the model for further\n        use.\n\n        Internally, `batch_ndims` is set to `1` by default to correctly handle the batch\n        dimensions of the posterior samples. For more information, refer to the\n        [NumPyro documentation](https://num.pyro.ai/en/stable/utilities.html#predictive).\n\n        Args:\n            posterior_sample (dict[str, Array]): Posterior samples to set for the model.\n            return_sites (tuple[str] | None, optional): Names of variable (sites) to\n                return in `.predict()`. By default, it is set to `self.param_output`.\n\n        Returns:\n            The model instance, treated as fitted with posterior samples set, enabling\n                method chaining.\n\n        Raises:\n            ValueError: If the batch shapes in `posterior_sample` are inconsistent.\n        \"\"\"\n        batch_ndims = 1\n        batch_shapes = {\n            sample.shape[:batch_ndims] for sample in posterior_sample.values()\n        }\n        if len(batch_shapes) &gt; 1:\n            msg = f\"Inconsistent batch shapes found in posterior_sample: {batch_shapes}\"\n            raise ValueError(msg)\n        (self.num_samples,) = batch_shapes.pop()\n        self.posterior = posterior_sample\n        self._return_sites = return_sites or (self.param_output,)\n        self._is_fitted = True\n        self._dt_posterior = _dict_to_datatree(self.posterior)\n\n        return self\n\n    def __sample_posterior_predictive(\n        self,\n        *,\n        fn_sample_posterior_predictive: Callable,\n        kernel: Callable,\n        X: ArrayLike | ArrayLoader,\n        rng_key: Array,\n        group: str,\n        return_sites: tuple[str],\n        batch_size: int | None,\n        output_dir: Path,\n        progress: bool,\n        **kwargs: object,\n    ) -&gt; xr.DataTree:\n        kwargs_array, kwargs_extra = _group_kwargs(kwargs)\n\n        dataloader, _ = _setup_inputs(\n            X=X,\n            y=None,\n            rng_key=self.rng_key,\n            batch_size=batch_size,\n            shuffle=False,\n            device=self._device,\n            **kwargs,\n        )\n\n        pbar = tqdm(\n            desc=(f\"Posterior predictive sampling [{', '.join(return_sites)}]\"),\n            total=len(dataloader),\n            disable=not progress,\n        )\n\n        rng_key, *subkeys = random.split(rng_key, num=len(dataloader) + 1)\n        if self._device and self._mesh:\n            subkeys = device_put(\n                subkeys,\n                NamedSharding(self._mesh, PartitionSpec()),\n            )\n\n        zarr_group = open_group(output_dir, mode=\"w\")\n        zarr_arr = {}\n        threads, queues, error_queue = _start_writer_threads(\n            return_sites,\n            group_path=output_dir,\n            writer=_writer,\n            queue_size=min(cpu_count() or 1, 4),\n        )\n        try:\n            for (batch, n_pad), subkey in zip(dataloader, subkeys, strict=True):\n                kwargs_batch = [\n                    v\n                    for k, v in batch.items()\n                    if k not in (self.param_input, self.param_output)\n                ]\n                dict_arr = device_get(\n                    fn_sample_posterior_predictive(\n                        kernel,\n                        self.num_samples,\n                        subkey,\n                        return_sites,\n                        self.posterior,\n                        self.param_input,\n                        kwargs_array._fields + kwargs_extra._fields,\n                        batch[self.param_input],\n                        *(*kwargs_batch, *kwargs_extra),\n                    ),\n                )\n                for site, arr in dict_arr.items():\n                    if site not in zarr_arr:\n                        zarr_arr[site] = zarr_group.create_array(\n                            name=site,\n                            shape=(self.num_samples, 0, *arr.shape[2:]),\n                            dtype=\"float32\" if arr.dtype == \"bfloat16\" else arr.dtype,\n                            chunks=(\n                                self.num_samples,\n                                dataloader.batch_size,\n                                *arr.shape[2:],\n                            ),\n                            dimension_names=(\n                                \"draw\",\n                                *tuple(f\"{site}_dim_{i}\" for i in range(arr.ndim - 1)),\n                            ),\n                        )\n                    queues[site].put(arr[:, : -n_pad or None])\n                if not error_queue.empty():\n                    _, exc, tb = error_queue.get()\n                    raise exc.with_traceback(tb)\n                pbar.update()\n            pbar.set_description(\"Sampling complete, writing in progress...\")\n            _shutdown_writer_threads(threads, queues)\n        except:\n            _shutdown_writer_threads(threads, queues)\n            logger.exception(\n                \"Exception encountered. Cleaning up output directory: %s\",\n                output_dir,\n            )\n            rmtree(output_dir, ignore_errors=True)\n            raise\n        finally:\n            pbar.close()\n\n        ds = open_zarr(output_dir, consolidated=False).expand_dims(dim=\"chain\", axis=0)\n        ds = ds.assign_coords(\n            {k: np.arange(ds.sizes[k]) for k in ds.sizes},\n        ).assign_attrs(_make_attrs())\n        out = xr.DataTree(name=\"root\")\n        out[\"posterior\"] = self._dt_posterior\n        out[group] = xr.DataTree(ds)\n\n        return out\n\n    def predict_on_batch(\n        self,\n        X: ArrayLike,\n        *,\n        intervention: dict | None = None,\n        rng_key: Array | None = None,\n        in_sample: bool = True,\n        return_sites: tuple[str] | None = None,\n        **kwargs: object,\n    ) -&gt; xr.DataTree:\n        \"\"\"Predict the output based on the fitted model.\n\n        This method returns predictions for a single batch of input data and is better\n        suited for:\n            1) Models incompatible with `.predict()` due to their posterior sample\n                shapes.\n            2) Scenarios where writing results to to files (e.g., disk, cloud storage)\n                is not desired.\n            3) Smaller datasets, as this method may be slower due to limited\n                parallelism.\n\n        Args:\n            X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n            intervention (dict | None, optional): A dictionary mapping sample sites to\n                their corresponding intervention values. Interventions enable\n                counterfactual analysis by modifying the specified sample sites during\n                prediction (posterior predictive sampling).\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed.\n            in_sample (bool, optional): Specifies the group where posterior predictive\n                samples are stored in the returned output. If `True`, samples are stored\n                in the `posterior_predictive` group, indicating they were generated\n                based on data used during model fitting. If `False`, samples are stored\n                in the `predictions` group, indicating they were generated based on\n                out-of-sample data.\n            return_sites (tuple[str] | None, optional): Names of variables (sites) to\n                return. If `None`, samples `self.param_output` and deterministic sites.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            Posterior predictive samples. Posterior samples are included if available.\n\n        Raises:\n            TypeError: If `self.param_output` is passed as an argument.\n        \"\"\"\n        _check_is_fitted(self)\n\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n\n        X = jnp.asarray(check_array(X))\n\n        # Validate the provided parameters against the kernel's signature\n        args_bound = (\n            signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n        )\n        if self.param_output in args_bound:\n            sub = self.param_output\n            msg = f\"{sub!r} is not allowed in `.predict_on_batch()`.\"\n            raise TypeError(msg)\n\n        if intervention is None:\n            kernel = self.kernel\n        else:\n            rng_key, rng_subkey = random.split(rng_key)\n            kernel = seed(do(self.kernel, data=intervention), rng_seed=rng_subkey)\n\n        out = xr.DataTree(name=\"root\")\n        out[\"posterior\"] = self._dt_posterior\n        out[\"posterior_predictive\" if in_sample else \"predictions\"] = _dict_to_datatree(\n            _sample_forward(\n                kernel,\n                rng_key=rng_key,\n                num_samples=self.num_samples,\n                return_sites=return_sites or self._return_sites,\n                posterior_samples=self.posterior,\n                model_kwargs=args_bound,\n            ),\n        )\n\n        return out\n\n    def predict(\n        self,\n        X: ArrayLike | ArrayLoader,\n        *,\n        intervention: dict | None = None,\n        rng_key: Array | None = None,\n        in_sample: bool = True,\n        return_sites: tuple[str] | None = None,\n        batch_size: int | None = None,\n        output_dir: str | Path | None = None,\n        progress: bool = True,\n        **kwargs: object,\n    ) -&gt; xr.DataTree:\n        \"\"\"Predict the output based on the fitted model.\n\n        This method performs posterior predictive sampling to generate model-based\n        predictions. It is optimized for batch processing of large input data and is not\n        recommended for use in loops that process only a few inputs at a time. Results\n        are written to disk in the Zarr format, with sampling and file writing decoupled\n        and executed concurrently.\n\n        Args:\n            X (ArrayLike | ArrayLoader): Input data, either an array-like of shape\n                `(n_samples, n_features)` or a data loader that holds all array-like\n                objects and handles batching internally; if a data loader is passed,\n                `batch_size` is ignored.\n            intervention (dict | None, optional): A dictionary mapping sample sites to\n                their corresponding intervention values. Interventions enable\n                counterfactual analysis by modifying the specified sample sites during\n                prediction (posterior predictive sampling).\n            rng_key (Array | None, optional): A pseudo-random number generator key. By\n                default, an internal key is used and split as needed.\n            in_sample (bool, optional): Specifies the group where posterior predictive\n                samples are stored in the returned output. If `True`, samples are stored\n                in the `posterior_predictive` group, indicating they were generated\n                based on data used during model fitting. If `False`, samples are stored\n                in the `predictions` group, indicating they were generated based on\n                out-of-sample data.\n            return_sites (tuple[str] | None, optional): Names of variables (sites) to\n                return. If `None`, samples `self.param_output` and deterministic sites.\n            batch_size (int | None, optional): The size of batches for data loading\n                during posterior predictive sampling. By default, it is set to the\n                total number of samples (`n_samples_X`). This value also determines the\n                chunk size for storing the posterior predictive samples.\n            output_dir (str | Path | None, optional): The directory where the outputs\n                will be saved. If the specified directory does not exist, it will be\n                created automatically. If `None`, a default temporary directory will be\n                created. A timestamped subdirectory will be generated within this\n                directory to store the outputs. Outputs are saved in the Zarr format.\n            progress (bool, optional): Whether to display a progress bar.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            Posterior predictive samples. Posterior samples are included if available.\n\n        Raises:\n            TypeError: If `self.param_output` is passed as an argument.\n        \"\"\"\n        _check_is_fitted(self)\n\n        # Check for compatibility with the `.predict()` method.\n        #\n        # If any array in the posterior has shape (num_samples, num_obs)\u2014i.e.,\n        # `ndim == 2` and the second dimension matches the number of observations in\n        # `X`\u2014it suggests that the model produces per-observation posterior samples.\n        # This makes it incompatible with the current `.predict()` implementation, which\n        # uses sharded parallelism. In such cases, fall back to `.predict_on_batch()`\n        # and raise a warning.\n        if isinstance(X, ArrayLike):\n            ndim_posterior_sample = 2\n            if self.posterior and any(\n                v.ndim == ndim_posterior_sample and v.shape[1] == len(X)\n                for v in self.posterior.values()\n            ):\n                msg = (\n                    \"One or more posterior sample shapes are not compatible with \"\n                    \"`.predict()` under sharded parallelism; falling back to \"\n                    \"`.predict_on_batch()`.\"\n                )\n                warn(msg, category=UserWarning, stacklevel=2)\n\n                return self.predict_on_batch(\n                    X,\n                    intervention=intervention,\n                    rng_key=rng_key,\n                    in_sample=in_sample,\n                    return_sites=return_sites or self._return_sites,\n                    **kwargs,\n                )\n            # Validate the provided parameters against the kernel's signature\n            args_bound = (\n                signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n            )\n            if self.param_output in args_bound:\n                sub = self.param_output\n                msg = f\"{sub!r} is not allowed in `.predict()`.\"\n                raise TypeError(msg)\n\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n\n        if intervention is None:\n            kernel = self.kernel\n        else:\n            rng_key, rng_subkey = random.split(rng_key)\n            kernel = seed(do(self.kernel, data=intervention), rng_seed=rng_subkey)\n\n        kwargs_array, kwargs_extra = _group_kwargs(kwargs)\n        if self._fn_sample_posterior_predictive is None:\n            self._fn_sample_posterior_predictive = _create_sharded_sampler(\n                self._mesh,\n                len(kwargs_array),\n                len(kwargs_extra),\n            )\n\n        if output_dir is None:\n            if not hasattr(self, \"temp_dir\"):\n                self.temp_dir = TemporaryDirectory()\n                logger.info(\n                    \"Temporary directory created at: %s\",\n                    self.temp_dir.name,\n                )\n            output_dir = self.temp_dir.name\n            logger.info(\n                \"No output directory provided. Using the model's temporary directory \"\n                \"for storing output.\",\n            )\n        output_subdir = _create_output_subdir(output_dir)\n\n        return self.__sample_posterior_predictive(\n            fn_sample_posterior_predictive=self._fn_sample_posterior_predictive,\n            kernel=kernel,\n            X=X,\n            rng_key=rng_key,\n            group=\"posterior_predictive\" if in_sample else \"predictions\",\n            return_sites=return_sites or self._return_sites,\n            batch_size=batch_size,\n            output_dir=output_subdir,\n            progress=progress,\n            **kwargs,\n        )\n\n    def estimate_effect(\n        self,\n        output_baseline: xr.DataTree | None = None,\n        output_intervention: xr.DataTree | None = None,\n        args_baseline: dict | None = None,\n        args_intervention: dict | None = None,\n    ) -&gt; xr.DataTree:\n        \"\"\"Estimate the effect of an intervention.\n\n        Args:\n            output_baseline (xr.DataTree | None, optional): Precomputed output for the\n                baseline scenario.\n            output_intervention (xr.DataTree | None, optional): Precomputed output for\n                the intervention scenario.\n            args_baseline (dict | None, optional): Input arguments for the baseline\n                scenario. Passed to the `.predict()` method to compute predictions if\n                `output_baseline` is not provided. Ignored if `output_baseline` is\n                already given.\n            args_intervention (dict | None, optional): Input arguments for the\n                intervention scenario. Passed to the `.predict()` method to compute\n                predictions if `output_intervention` is not provided. Ignored if\n                `output_intervention` is already given.\n\n        Returns:\n            The estimated impact of an intervention.\n\n        Raises:\n            ValueError: If neither `output_baseline` nor `args_baseline` is provided, or\n                if neither `output_intervention` nor `args_intervention` is provided.\n        \"\"\"\n        _check_is_fitted(self)\n\n        if output_baseline:\n            dt_baseline = output_baseline\n        elif args_baseline:\n            dt_baseline = self.predict(**args_baseline)\n        else:\n            msg = \"Either `output_baseline` or `args_baseline` must be provided.\"\n            raise ValueError(msg)\n\n        if output_intervention:\n            dt_intervention = output_intervention\n        elif args_intervention:\n            dt_intervention = self.predict(**args_intervention)\n        else:\n            msg = (\n                \"Either `output_intervention` or `args_intervention` must be provided.\"\n            )\n            raise ValueError(msg)\n\n        group = _validate_group(dt_baseline, dt_intervention)\n\n        out = xr.DataTree(name=\"root\")\n        out[group] = dt_intervention[group] - dt_baseline[group]\n\n        return out\n\n    def log_likelihood(\n        self,\n        X: ArrayLike | ArrayLoader,\n        y: ArrayLike | None = None,\n        *,\n        batch_size: int | None = None,\n        output_dir: str | Path | None = None,\n        progress: bool = True,\n        **kwargs: object,\n    ) -&gt; xr.DataTree:\n        \"\"\"Compute the log likelihood of the data under the given model.\n\n        Results are written to disk in the Zarr format, with computing and file writing\n        decoupled and executed concurrently.\n\n        Args:\n            X (ArrayLike | ArrayLoader): Input data, either an array-like of shape\n                `(n_samples, n_features)` or a data loader that holds all array-like\n                objects and handles batching internally; if a data loader is passed,\n                `batch_size` is ignored.\n            y (ArrayLike | None): Output data with shape `(n_samples_Y,)`. Must be\n                `None` if `X` is a data loader.\n            batch_size (int | None, optional): The size of batches for data loading\n                during posterior predictive sampling. By default, it is set to the total\n                number of samples (`n_samples_X`). This value also determines the chunk\n                size for storing the log-likelihood values.\n            output_dir (str | Path | None, optional): The directory where the outputs\n                will be saved. If the specified directory does not exist, it will be\n                created automatically. If `None`, a default temporary directory will be\n                created. A timestamped subdirectory will be generated within this\n                directory to store the outputs. Outputs are saved in the Zarr format.\n            progress (bool, optional): Whether to display a progress bar.\n            **kwargs (object): Additional arguments passed to the model. All array-like\n                values are expected to be JAX arrays.\n\n        Returns:\n            Log-likelihood values. Posterior samples are included if available.\n        \"\"\"\n        _check_is_fitted(self)\n\n        kwargs_array, kwargs_extra = _group_kwargs(kwargs)\n        if self._fn_log_likelihood is None:\n            self._fn_log_likelihood = _create_sharded_log_likelihood(\n                self._mesh,\n                len(kwargs_array),\n                len(kwargs_extra),\n            )\n\n        if output_dir is None:\n            if not hasattr(self, \"temp_dir\"):\n                self.temp_dir = TemporaryDirectory()\n                logger.info(\n                    \"Temporary directory created at: %s\",\n                    self.temp_dir.name,\n                )\n            output_dir = self.temp_dir.name\n            logger.info(\n                \"No output directory provided. Using the model's temporary directory \"\n                \"for storing output.\",\n            )\n        output_subdir = _create_output_subdir(output_dir)\n\n        dataloader, _ = _setup_inputs(\n            X=X,\n            y=y,\n            rng_key=self.rng_key,\n            batch_size=batch_size,\n            shuffle=False,\n            device=self._device,\n            **kwargs,\n        )\n\n        site = self.param_output\n        pbar = tqdm(\n            desc=(f\"Computing log-likelihood of {site}...\"),\n            total=len(dataloader),\n            disable=not progress,\n        )\n\n        zarr_group = open_group(output_subdir, mode=\"w\")\n        zarr_arr = {}\n        threads, queues, error_queue = _start_writer_threads(\n            (site,),\n            group_path=output_subdir,\n            writer=_writer,\n            queue_size=min(cpu_count() or 1, 4),\n        )\n        try:\n            for batch, n_pad in dataloader:\n                kwargs_batch = [\n                    v\n                    for k, v in batch.items()\n                    if k not in (self.param_input, self.param_output)\n                ]\n                arr = device_get(\n                    self._fn_log_likelihood(\n                        # Although computing the log-likelihood is deterministic, the\n                        # model still needs to be seeded in order to trace its graph.\n                        seed(self.kernel, rng_seed=self.rng_key),\n                        self.posterior,\n                        self.param_input,\n                        site,\n                        kwargs_array._fields + kwargs_extra._fields,\n                        batch[self.param_input],\n                        batch[self.param_output],\n                        *(*kwargs_batch, *kwargs_extra),\n                    ),\n                )\n                if site not in zarr_arr:\n                    zarr_arr[site] = zarr_group.create_array(\n                        name=site,\n                        shape=(self.num_samples, 0, *arr.shape[2:]),\n                        dtype=\"float32\" if arr.dtype == \"bfloat16\" else arr.dtype,\n                        chunks=(\n                            self.num_samples,\n                            dataloader.batch_size,\n                            *arr.shape[2:],\n                        ),\n                        dimension_names=(\n                            \"draw\",\n                            *tuple(f\"{site}_dim_{i}\" for i in range(arr.ndim - 1)),\n                        ),\n                    )\n                queues[site].put(arr[:, : -n_pad or None])\n                if not error_queue.empty():\n                    _, exc, tb = error_queue.get()\n                    raise exc.with_traceback(tb)\n                pbar.update()\n            pbar.set_description(\"Computation complete, writing in progress...\")\n            _shutdown_writer_threads(threads, queues=queues)\n        except:\n            _shutdown_writer_threads(threads, queues=queues)\n            logger.exception(\n                \"Exception encountered. Cleaning up output directory: %s\",\n                output_subdir,\n            )\n            rmtree(output_subdir, ignore_errors=True)\n            raise\n        finally:\n            pbar.close()\n\n        ds = open_zarr(output_subdir, consolidated=False).expand_dims(\n            dim=\"chain\",\n            axis=0,\n        )\n        ds = ds.assign_coords(\n            {k: np.arange(ds.sizes[k]) for k in ds.sizes},\n        ).assign_attrs(_make_attrs())\n        out = xr.DataTree(name=\"root\")\n        out[\"posterior\"] = self._dt_posterior\n        out[\"log_likelihood\"] = xr.DataTree(ds)\n\n        return out\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up the temporary directory created for storing outputs.\n\n        If the temporary directory was never created or has already been cleaned up,\n        this method does nothing. It does not delete any explicitly specified output\n        directory. While the temporary directory is typically removed automatically\n        during garbage collection, this behavior is not guaranteed. Therefore, calling\n        this method explicitly is recommended to ensure timely resource release.\n        \"\"\"\n        if hasattr(self, \"temp_dir\"):\n            logger.info(\"Temporary directory cleaned up at: %s\", self.temp_dir.name)\n            self.temp_dir.cleanup()\n            del self.temp_dir\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.vi_result","title":"vi_result  <code>property</code> <code>writable</code>","text":"<pre><code>vi_result: SVIRunResult\n</code></pre> <p>Get the current variational inference result.</p> <p>Returns:</p> Type Description <code>SVIRunResult</code> <p>The stored result from variational inference.</p>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.__init__","title":"__init__","text":"<pre><code>__init__(kernel: Callable, rng_key: Array, inference: SVI | MCMC, *, param_input: str = 'X', param_output: str = 'y') -&gt; None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Callable</code> <p>A probabilistic model with Pyro primitives.</p> required <code>rng_key</code> <code>Array</code> <p>A pseudo-random number generator key.</p> required <code>inference</code> <code>SVI | MCMC</code> <p>An inference method supported by NumPyro, such as an instance of <code>numpyro.infer.svi.SVI</code> or <code>numpyro.infer.mcmc.MCMC</code>.</p> required <code>param_input</code> <code>str</code> <p>The name of the parameter in the <code>kernel</code> for the main input data.</p> <code>'X'</code> <code>param_output</code> <code>str</code> <p>The name of the parameter in the <code>kernel</code> for the output data.</p> <code>'y'</code> Warning <p>The <code>rng_key</code> parameter should be provided as a typed key array created with <code>jax.random.key()</code>, rather than a legacy <code>uint32</code> key created with <code>jax.random.PRNGKey()</code>.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def __init__(\n    self,\n    kernel: Callable,\n    rng_key: Array,\n    inference: SVI | MCMC,\n    *,\n    param_input: str = \"X\",\n    param_output: str = \"y\",\n) -&gt; None:\n    \"\"\"Initialize an ImpactModel instance.\n\n    Args:\n        kernel (Callable): A probabilistic model with Pyro primitives.\n        rng_key (Array): A pseudo-random number generator key.\n        inference (SVI | MCMC): An inference method supported by NumPyro, such\n            as an instance of `numpyro.infer.svi.SVI` or `numpyro.infer.mcmc.MCMC`.\n        param_input (str, optional): The name of the parameter in the `kernel` for\n            the main input data.\n        param_output (str, optional): The name of the parameter in the `kernel` for\n            the output data.\n\n    Warning:\n        The `rng_key` parameter should be provided as a **typed key array**\n        created with `jax.random.key()`, rather than a legacy `uint32` key created\n        with `jax.random.PRNGKey()`.\n    \"\"\"\n    super().__init__(kernel, param_input, param_output)\n    if rng_key.dtype == jnp.uint32:\n        msg = \"Legacy `uint32` PRNGKey detected; converting to a typed key array.\"\n        warn(msg, category=UserWarning, stacklevel=2)\n        rng_key = random.wrap_key_data(rng_key)\n    self.rng_key = rng_key\n    if not isinstance(inference, (SVI, MCMC)):\n        msg = (\n            f\"Unsupported inference object: `{type(inference).__name__}`. \"\n            \"Expected `SVI` or `MCMC` from `numpyro.infer`.\"\n        )\n        raise TypeError(msg)\n    self.inference = inference\n    self._vi_state = None\n    self.posterior: dict[str, Array] | None = None\n    self._init_runtime_attrs()\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.__del__","title":"__del__","text":"<pre><code>__del__() -&gt; None\n</code></pre> <p>Clean up the temporary directory when the instance is deleted.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def __del__(self) -&gt; None:\n    \"\"\"Clean up the temporary directory when the instance is deleted.\"\"\"\n    self.cleanup()\n    # Call the parent's __del__ method only if it exists and is callable\n    super_del = getattr(super(), \"__del__\", None)\n    if callable(super_del):\n        super_del()\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.__getstate__","title":"__getstate__","text":"<pre><code>__getstate__() -&gt; dict\n</code></pre> <p>Return the state of the object excluding runtime attributes.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The state of the object, excluding runtime attributes.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def __getstate__(self) -&gt; dict:\n    \"\"\"Return the state of the object excluding runtime attributes.\n\n    Returns:\n        The state of the object, excluding runtime attributes.\n    \"\"\"\n    return {\n        k: v\n        for k, v in self.__dict__.items()\n        if not (\n            k.startswith(\"_fn\")\n            or k in {\"_device\", \"_mesh\", \"_num_devices\", \"temp_dir\"}\n        )\n    }\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.__setstate__","title":"__setstate__","text":"<pre><code>__setstate__(state: dict[str, object]) -&gt; None\n</code></pre> <p>Restore the state and reinitialize runtime attributes.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict</code> <p>The state to restore, excluding the runtime attributes.</p> required Source code in <code>aimz/model/impact_model.py</code> <pre><code>def __setstate__(self, state: dict[str, object]) -&gt; None:\n    \"\"\"Restore the state and reinitialize runtime attributes.\n\n    Args:\n        state (dict): The state to restore, excluding the runtime attributes.\n    \"\"\"\n    self.__dict__.update(state)\n    self._init_runtime_attrs()\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.sample_prior_predictive","title":"sample_prior_predictive","text":"<pre><code>sample_prior_predictive(X: ArrayLike, *, num_samples: int = 1000, rng_key: Array | None = None, return_sites: tuple[str] | None = None, **kwargs: object) -&gt; dict[str, Array]\n</code></pre> <p>Draw samples from the prior predictive distribution.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input data with shape <code>(n_samples_X, n_features)</code>.</p> required <code>num_samples</code> <code>int</code> <p>The number of samples to draw.</p> <code>1000</code> <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed.</p> <code>None</code> <code>return_sites</code> <code>tuple[str] | None</code> <p>Names of variables (sites) to return. If <code>None</code>, samples all latent, observed, and deterministic sites.</p> <code>None</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Array]</code> <p>Prior predictive samples.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>self.param_output</code> is passed as an argument.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def sample_prior_predictive(\n    self,\n    X: ArrayLike,\n    *,\n    num_samples: int = 1000,\n    rng_key: Array | None = None,\n    return_sites: tuple[str] | None = None,\n    **kwargs: object,\n) -&gt; dict[str, Array]:\n    \"\"\"Draw samples from the prior predictive distribution.\n\n    Args:\n        X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n        num_samples (int, optional): The number of samples to draw.\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed.\n        return_sites (tuple[str] | None, optional): Names of variables (sites) to\n            return. If `None`, samples all latent, observed, and deterministic\n            sites.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        Prior predictive samples.\n\n    Raises:\n        TypeError: If `self.param_output` is passed as an argument.\n    \"\"\"\n    if rng_key is None:\n        self.rng_key, rng_key = random.split(self.rng_key)\n\n    # Validate the provided parameters against the kernel's signature\n    args_bound = (\n        signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n    )\n    if self.param_output in args_bound:\n        sub = self.param_output\n        msg = f\"{sub!r} is not allowed in `.sample_prior_predictive()`.\"\n        raise TypeError(msg)\n\n    return _sample_forward(\n        self.kernel,\n        rng_key=rng_key,\n        num_samples=num_samples,\n        return_sites=return_sites,\n        posterior_samples=None,\n        model_kwargs=args_bound,\n    )\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.sample","title":"sample","text":"<pre><code>sample(num_samples: int = 1000, rng_key: Array | None = None, return_sites: tuple[str] | None = None, **kwargs: object) -&gt; dict[str, Array]\n</code></pre> <p>Draw posterior samples from a fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>num_samples</code> <code>int</code> <p>The number of posterior samples to draw.</p> <code>1000</code> <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed. Has no effect if the inference method is MCMC, where the <code>post_warmup_state</code> property will be used to continue sampling.</p> <code>None</code> <code>return_sites</code> <code>tuple[str] | None</code> <p>Names of variables (sites) to return. If <code>None</code>, samples all latent sites. Has no effect if the inference method is MCMC.</p> <code>None</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays. Only relevant when the inference method is MCMC.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Array]</code> <p>Posterior samples.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def sample(\n    self,\n    num_samples: int = 1000,\n    rng_key: Array | None = None,\n    return_sites: tuple[str] | None = None,\n    **kwargs: object,\n) -&gt; dict[str, Array]:\n    \"\"\"Draw posterior samples from a fitted model.\n\n    Args:\n        num_samples (int, optional): The number of posterior samples to draw.\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed. Has no effect if\n            the inference method is MCMC, where the `post_warmup_state` property\n            will be used to continue sampling.\n        return_sites (tuple[str] | None, optional): Names of variables (sites) to\n            return. If `None`, samples all latent sites. Has no effect if the\n            inference method is MCMC.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays. Only relevant when the inference\n            method is MCMC.\n\n    Returns:\n        Posterior samples.\n\n    \"\"\"\n    _check_is_fitted(self)\n\n    if rng_key is None:\n        self.rng_key, rng_key = random.split(self.rng_key)\n\n    if isinstance(self.inference, MCMC):\n        # Validate the provided parameters against the kernel's signature\n        args_bound = signature(self.kernel).bind(**kwargs).arguments\n        if self.param_output not in args_bound:\n            msg = f\"{self.param_output!r} must be provided in `.sample()`.\"\n            raise TypeError(msg)\n        self.inference.post_warmup_state = self.inference.last_state\n        self.inference.num_samples = num_samples\n        self.inference.run(self.inference.post_warmup_state.rng_key, **args_bound)\n\n        return device_get(self.inference.get_samples())\n\n    return _sample_forward(\n        substitute(self.inference.guide, data=self.vi_result.params),\n        rng_key=rng_key,\n        num_samples=num_samples,\n        return_sites=return_sites,\n        posterior_samples=None,\n        model_kwargs=None,\n    )\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.sample_posterior_predictive","title":"sample_posterior_predictive","text":"<pre><code>sample_posterior_predictive(X: ArrayLike, *, rng_key: Array | None = None, return_sites: tuple[str] | None = None, intervention: dict | None = None, **kwargs: object) -&gt; dict[str, Array]\n</code></pre> <p>Draw samples from the posterior predictive distribution.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input data with shape <code>(n_samples_X, n_features)</code>.</p> required <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed.</p> <code>None</code> <code>return_sites</code> <code>tuple[str] | None</code> <p>Names of variables (sites) to return. If <code>None</code>, samples <code>self.param_output</code> and deterministic sites.</p> <code>None</code> <code>intervention</code> <code>dict | None</code> <p>A dictionary mapping sample sites to their corresponding intervention values. Interventions enable counterfactual analysis by modifying the specified sample sites during prediction (posterior predictive sampling).</p> <code>None</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Array]</code> <p>Posterior predictive samples.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>self.param_output</code> is passed as an argument.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def sample_posterior_predictive(\n    self,\n    X: ArrayLike,\n    *,\n    rng_key: Array | None = None,\n    return_sites: tuple[str] | None = None,\n    intervention: dict | None = None,\n    **kwargs: object,\n) -&gt; dict[str, Array]:\n    \"\"\"Draw samples from the posterior predictive distribution.\n\n    Args:\n        X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed.\n        return_sites (tuple[str] | None, optional): Names of variables (sites) to\n            return. If `None`, samples `self.param_output` and deterministic sites.\n        intervention (dict | None, optional): A dictionary mapping sample sites to\n            their corresponding intervention values. Interventions enable\n            counterfactual analysis by modifying the specified sample sites during\n            prediction (posterior predictive sampling).\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        Posterior predictive samples.\n\n    Raises:\n        TypeError: If `self.param_output` is passed as an argument.\n    \"\"\"\n    _check_is_fitted(self)\n\n    if rng_key is None:\n        self.rng_key, rng_key = random.split(self.rng_key)\n\n    X = jnp.asarray(check_array(X))\n\n    # Validate the provided parameters against the kernel's signature\n    args_bound = (\n        signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n    )\n    if self.param_output in args_bound:\n        sub = self.param_output\n        msg = f\"{sub!r} is not allowed in `.sample_prior_predictive()`.\"\n        raise TypeError(msg)\n\n    if intervention is None:\n        kernel = self.kernel\n    else:\n        rng_key, rng_subkey = random.split(rng_key)\n        kernel = seed(do(self.kernel, data=intervention), rng_seed=rng_subkey)\n\n    return _sample_forward(\n        kernel,\n        rng_key=rng_key,\n        num_samples=self.num_samples,\n        return_sites=return_sites or self._return_sites,\n        posterior_samples=self.posterior,\n        model_kwargs=args_bound,\n    )\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.train_on_batch","title":"train_on_batch","text":"<pre><code>train_on_batch(X: ArrayLike, y: ArrayLike, rng_key: Array | None = None, **kwargs: object) -&gt; tuple[SVIState, Array]\n</code></pre> <p>Run a single VI step on the given batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input data with shape <code>(n_samples_X, n_features)</code>.</p> required <code>y</code> <code>ArrayLike</code> <p>Output data with shape <code>(n_samples_Y,)</code>.</p> required <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed. The key is only used for initialization if the internal SVI state is not yet set.</p> <code>None</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>SVIState</code> <p>Updated SVI state after the training step.</p> <code>ArrayLike</code> <p>Loss value as a scalar array.</p> Note <p>This method updates the internal SVI state on every call, so it is not necessary to capture the returned state externally unless explicitly needed. However, the returned loss value can be used for monitoring or logging.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def train_on_batch(\n    self,\n    X: ArrayLike,\n    y: ArrayLike,\n    rng_key: Array | None = None,\n    **kwargs: object,\n) -&gt; tuple[SVIState, Array]:\n    \"\"\"Run a single VI step on the given batch of data.\n\n    Args:\n        X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n        y (ArrayLike): Output data with shape `(n_samples_Y,)`.\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed. The key is only\n            used for initialization if the internal SVI state is not yet set.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        (SVIState): Updated SVI state after the training step.\n        (ArrayLike): Loss value as a scalar array.\n\n    Note:\n        This method updates the internal SVI state on every call, so it is not\n        necessary to capture the returned state externally unless explicitly needed.\n        However, the returned loss value can be used for monitoring or logging.\n    \"\"\"\n    batch = {self.param_input: X, self.param_output: y, **kwargs}\n\n    if self._vi_state is None:\n        # Validate the provided parameters against the kernel's signature\n        model_trace = trace(seed(self.kernel, rng_seed=self.rng_key)).get_trace(\n            **signature(self.kernel).bind(**batch).arguments,\n        )\n        # Validate the kernel body for output sample site and naming conflicts\n        _validate_kernel_body(\n            self.kernel,\n            self.param_output,\n            model_trace,\n        )\n        self._return_sites = (\n            *(\n                k\n                for k, site in model_trace.items()\n                if site[\"type\"] == \"deterministic\"\n            ),\n            self.param_output,\n        )\n        if rng_key is None:\n            self.rng_key, rng_key = random.split(self.rng_key)\n        self._vi_state = self.inference.init(rng_key, **batch)\n    if self._fn_vi_update is None:\n        _, kwargs_extra = _group_kwargs(kwargs)\n        self._fn_vi_update = jit(\n            self.inference.update,\n            static_argnames=tuple(kwargs_extra._fields),\n        )\n\n    self._vi_state, loss = self._fn_vi_update(self._vi_state, **batch)\n\n    return self._vi_state, loss\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.fit_on_batch","title":"fit_on_batch","text":"<pre><code>fit_on_batch(X: ArrayLike, y: ArrayLike, *, num_steps: int = 10000, num_samples: int = 1000, rng_key: Array | None = None, progress: bool = True, **kwargs: object) -&gt; Self\n</code></pre> <p>Fit the impact model to the provided batch of data.</p> <p>This method behaves differently depending on the inference method specified at initialization of the ImpactModel instance:</p> <ul> <li> <p>SVI: Runs variational inference on the provided batch by invoking the <code>run()</code> method of the <code>SVI</code> instance from NumPyro to estimate the posterior distribution, then draws samples from it.</p> </li> <li> <p>MCMC: Runs posterior sampling by invoking the <code>run()</code> method of the <code>MCMC</code>     instance from NumPyro.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input data with shape <code>(n_samples_X, n_features)</code>.</p> required <code>y</code> <code>ArrayLike</code> <p>Output data with shape <code>(n_samples_Y,)</code>.</p> required <code>num_steps</code> <code>int</code> <p>Number of steps for variational inference optimization. Has no effect if the inference method is MCMC.</p> <code>10000</code> <code>num_samples</code> <code>int | None</code> <p>The number of posterior samples to draw. Has no effect if the inference method is MCMC.</p> <code>1000</code> <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed.</p> <code>None</code> <code>progress</code> <code>bool</code> <p>Whether to display a progress bar. Has no effect if the inference method is MCMC.</p> <code>True</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The fitted model instance, enabling method chaining.</p> Note <p>This method continues training from the existing SVI state if available. To start training from scratch, create a new model instance.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def fit_on_batch(\n    self,\n    X: ArrayLike,\n    y: ArrayLike,\n    *,\n    num_steps: int = 10000,\n    num_samples: int = 1000,\n    rng_key: Array | None = None,\n    progress: bool = True,\n    **kwargs: object,\n) -&gt; Self:\n    \"\"\"Fit the impact model to the provided batch of data.\n\n    This method behaves differently depending on the inference method specified at\n    initialization of the ImpactModel instance:\n\n    - **SVI:** Runs variational inference on the provided batch by invoking the\n    `run()` method of the `SVI` instance from NumPyro to estimate the posterior\n    distribution, then draws samples from it.\n\n    - **MCMC:** Runs posterior sampling by invoking the `run()` method of the `MCMC`\n        instance from NumPyro.\n\n    Args:\n        X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n        y (ArrayLike): Output data with shape `(n_samples_Y,)`.\n        num_steps (int, optional): Number of steps for variational inference\n            optimization. Has no effect if the inference method is MCMC.\n        num_samples (int | None, optional): The number of posterior samples to draw.\n            Has no effect if the inference method is MCMC.\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed.\n        progress (bool, optional): Whether to display a progress bar. Has no effect\n            if the inference method is MCMC.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        The fitted model instance, enabling method chaining.\n\n    Note:\n        This method continues training from the existing SVI state if available. To\n        start training from scratch, create a new model instance.\n    \"\"\"\n    if rng_key is None:\n        self.rng_key, rng_key = random.split(self.rng_key)\n\n    X, y = map(jnp.asarray, check_X_y(X, y, force_writeable=True, y_numeric=True))\n\n    # Validate the provided parameters against the kernel's signature\n    args_bound = (\n        signature(self.kernel)\n        .bind(**{self.param_input: X, self.param_output: y, **kwargs})\n        .arguments\n    )\n    model_trace = trace(seed(self.kernel, rng_seed=self.rng_key)).get_trace(\n        **args_bound,\n    )\n    # Validate the kernel body for output sample site and naming conflicts\n    _validate_kernel_body(\n        self.kernel,\n        self.param_output,\n        model_trace,\n    )\n    self._return_sites = (\n        *(k for k, site in model_trace.items() if site[\"type\"] == \"deterministic\"),\n        self.param_output,\n    )\n\n    rng_key, rng_subkey = random.split(rng_key)\n    if isinstance(self.inference, SVI):\n        self.num_samples = num_samples\n        logger.info(\"Performing variational inference optimization...\")\n        self.vi_result = self.inference.run(\n            rng_subkey,\n            num_steps=num_steps,\n            progress_bar=progress,\n            init_state=self._vi_state,\n            **args_bound,\n        )\n        self._vi_state = self.vi_result.state\n        if np.any(np.isnan(self.vi_result.losses)):\n            warn(\n                \"Loss contains NaN or Inf, indicating numerical instability.\",\n                category=RuntimeWarning,\n                stacklevel=2,\n            )\n        logger.info(\"Posterior sampling...\")\n        rng_key, rng_subkey = random.split(rng_key)\n        self.posterior = self.sample(self.num_samples, rng_key=rng_subkey)\n    elif isinstance(self.inference, MCMC):\n        logger.info(\"Posterior sampling...\")\n        self.inference.run(rng_subkey, **args_bound)\n        self.posterior = device_get(self.inference.get_samples())\n        self.num_samples = (\n            next(iter(self.posterior.values())).shape[0] if self.posterior else 0\n        )\n\n    self._is_fitted = True\n    self._dt_posterior = (\n        _dict_to_datatree(self.posterior) if self.posterior else None\n    )\n\n    return self\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.fit","title":"fit","text":"<pre><code>fit(X: ArrayLike | ArrayLoader, y: ArrayLike | None = None, *, num_samples: int = 1000, rng_key: Array | None = None, progress: bool = True, batch_size: int | None = None, epochs: int = 1, shuffle: bool = True, **kwargs: object) -&gt; Self\n</code></pre> <p>Fit the impact model to the provided data using epoch-based training.</p> <p>This method implements an epoch-based training loop, where the data is iterated over in minibatches for a specified number of epochs. Variational inference is performed by repeatedly updating the model parameters on each minibatch, and then posterior samples are drawn from the fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike | ArrayLoader</code> <p>Input data, either an array-like of shape <code>(n_samples, n_features)</code> or a data loader that holds all array-like objects and handles batching internally; if a data loader is passed, <code>batch_size</code> is ignored.</p> required <code>y</code> <code>ArrayLike | None</code> <p>Output data with shape <code>(n_samples_Y,)</code>. Must be <code>None</code> if <code>X</code> is a data loader.</p> <code>None</code> <code>num_samples</code> <code>int | None</code> <p>The number of posterior samples to draw.</p> <code>1000</code> <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed.</p> <code>None</code> <code>progress</code> <code>bool</code> <p>Whether to display a progress bar.</p> <code>True</code> <code>batch_size</code> <code>int | None</code> <p>The number of data points processed at each step of variational inference. If <code>None</code> (default), the entire dataset is used as a single batch in each epoch.</p> <code>None</code> <code>epochs</code> <code>int</code> <p>The number of epochs for variational inference optimization.</p> <code>1</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the data at each epoch.</p> <code>True</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The fitted model instance, enabling method chaining.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the inference method is MCMC.</p> Note <p>This method continues training from the existing SVI state if available. To start training from scratch, create a new model instance. It does not check whether the model or guide is written to support subsampling semantics (e.g., using NumPyro's <code>subsample</code> or similar constructs).</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def fit(\n    self,\n    X: ArrayLike | ArrayLoader,\n    y: ArrayLike | None = None,\n    *,\n    num_samples: int = 1000,\n    rng_key: Array | None = None,\n    progress: bool = True,\n    batch_size: int | None = None,\n    epochs: int = 1,\n    shuffle: bool = True,\n    **kwargs: object,\n) -&gt; Self:\n    \"\"\"Fit the impact model to the provided data using epoch-based training.\n\n    This method implements an epoch-based training loop, where the data is iterated\n    over in minibatches for a specified number of epochs. Variational inference is\n    performed by repeatedly updating the model parameters on each minibatch, and\n    then posterior samples are drawn from the fitted model.\n\n    Args:\n        X (ArrayLike | ArrayLoader): Input data, either an array-like of shape\n            `(n_samples, n_features)` or a data loader that holds all array-like\n            objects and handles batching internally; if a data loader is passed,\n            `batch_size` is ignored.\n        y (ArrayLike | None): Output data with shape `(n_samples_Y,)`. Must be\n            `None` if `X` is a data loader.\n        num_samples (int | None, optional): The number of posterior samples to draw.\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed.\n        progress (bool, optional): Whether to display a progress bar.\n        batch_size (int | None, optional): The number of data points processed at\n            each step of variational inference. If `None` (default), the entire\n            dataset is used as a single batch in each epoch.\n        epochs (int, optional): The number of epochs for variational inference\n            optimization.\n        shuffle (bool, optional): Whether to shuffle the data at each epoch.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        The fitted model instance, enabling method chaining.\n\n    Raises:\n        TypeError: If the inference method is MCMC.\n\n    Note:\n        This method continues training from the existing SVI state if available.\n        To start training from scratch, create a new model instance. It does not\n        check whether the model or guide is written to support subsampling semantics\n        (e.g., using NumPyro's `subsample` or similar constructs).\n    \"\"\"\n    if isinstance(self.inference, MCMC):\n        msg = (\n            \"`.fit()` is not supported for MCMC inference. Use `.fit_on_batch()` \"\n            \"instead.\"\n        )\n        raise TypeError(msg)\n\n    if rng_key is None:\n        self.rng_key, rng_key = random.split(self.rng_key)\n\n    self.num_samples = num_samples\n\n    rng_key, rng_subkey = random.split(rng_key)\n    dataloader, kwargs_extra = _setup_inputs(\n        X=X,\n        y=y,\n        rng_key=rng_subkey,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        device=None,\n        **kwargs,\n    )\n\n    logger.info(\"Performing variational inference optimization...\")\n    losses: list[float] = []\n    rng_key, rng_subkey = random.split(rng_key)\n    for epoch in range(epochs):\n        losses_epoch: list[float] = []\n        pbar = tqdm(\n            dataloader,\n            total=len(dataloader),\n            desc=f\"Epoch {epoch + 1}/{epochs}\",\n            disable=not progress,\n        )\n        for batch, _ in pbar:\n            self._vi_state, loss = self.train_on_batch(\n                **batch,\n                **kwargs_extra._asdict(),\n                rng_key=rng_subkey,\n            )\n            loss_batch = device_get(loss)\n            losses_epoch.append(loss_batch)\n            pbar.set_postfix({\"loss\": f\"{float(loss_batch):.4f}\"})\n        losses_epoch_arr = jnp.stack(losses_epoch)\n        losses.extend(losses_epoch_arr)\n        tqdm.write(\n            f\"Epoch {epoch + 1}/{epochs} - \"\n            f\"Average loss: {float(jnp.mean(losses_epoch_arr)):.4f}\",\n        )\n    self.vi_result = SVIRunResult(\n        params=self.inference.get_params(self._vi_state),\n        state=self._vi_state,\n        losses=jnp.asarray(losses),\n    )\n    if np.any(np.isnan(self.vi_result.losses)):\n        msg = \"Loss contains NaN or Inf, indicating numerical instability.\"\n        warn(msg, category=RuntimeWarning, stacklevel=2)\n\n    self._is_fitted = True\n\n    logger.info(\"Posterior sampling...\")\n    rng_key, rng_subkey = random.split(rng_key)\n    self.posterior = self.sample(self.num_samples, rng_key=rng_subkey)\n    self._dt_posterior = (\n        _dict_to_datatree(self.posterior) if self.posterior else None\n    )\n\n    return self\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.is_fitted","title":"is_fitted","text":"<pre><code>is_fitted() -&gt; bool\n</code></pre> <p>Check fitted status.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the model is fitted, <code>False</code> otherwise.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def is_fitted(self) -&gt; bool:\n    \"\"\"Check fitted status.\n\n    Returns:\n        `True` if the model is fitted, `False` otherwise.\n\n    \"\"\"\n    return hasattr(self, \"_is_fitted\") and self._is_fitted\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.set_posterior_sample","title":"set_posterior_sample","text":"<pre><code>set_posterior_sample(posterior_sample: dict[str, Array], return_sites: tuple[str] | None = None) -&gt; Self\n</code></pre> <p>Set posterior samples for the model.</p> <p>This method sets externally obtained posterior samples on the model instance, enabling downstream analysis without requiring a call to <code>.fit()</code> or <code>.fit_on_batch()</code>.</p> <p>It is primarily intended for workflows where posterior sampling is performed manually\u2014for example, using NumPyro's <code>SVI</code> (or <code>MCMC</code>) with the <code>Predictive</code> API\u2014and the resulting posterior samples are injected into the model for further use.</p> <p>Internally, <code>batch_ndims</code> is set to <code>1</code> by default to correctly handle the batch dimensions of the posterior samples. For more information, refer to the NumPyro documentation.</p> <p>Parameters:</p> Name Type Description Default <code>posterior_sample</code> <code>dict[str, Array]</code> <p>Posterior samples to set for the model.</p> required <code>return_sites</code> <code>tuple[str] | None</code> <p>Names of variable (sites) to return in <code>.predict()</code>. By default, it is set to <code>self.param_output</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The model instance, treated as fitted with posterior samples set, enabling method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the batch shapes in <code>posterior_sample</code> are inconsistent.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def set_posterior_sample(\n    self,\n    posterior_sample: dict[str, Array],\n    return_sites: tuple[str] | None = None,\n) -&gt; Self:\n    \"\"\"Set posterior samples for the model.\n\n    This method sets externally obtained posterior samples on the model instance,\n    enabling downstream analysis without requiring a call to `.fit()` or\n    `.fit_on_batch()`.\n\n    It is primarily intended for workflows where posterior sampling is performed\n    manually\u2014for example, using NumPyro's `SVI` (or `MCMC`) with the `Predictive`\n    API\u2014and the resulting posterior samples are injected into the model for further\n    use.\n\n    Internally, `batch_ndims` is set to `1` by default to correctly handle the batch\n    dimensions of the posterior samples. For more information, refer to the\n    [NumPyro documentation](https://num.pyro.ai/en/stable/utilities.html#predictive).\n\n    Args:\n        posterior_sample (dict[str, Array]): Posterior samples to set for the model.\n        return_sites (tuple[str] | None, optional): Names of variable (sites) to\n            return in `.predict()`. By default, it is set to `self.param_output`.\n\n    Returns:\n        The model instance, treated as fitted with posterior samples set, enabling\n            method chaining.\n\n    Raises:\n        ValueError: If the batch shapes in `posterior_sample` are inconsistent.\n    \"\"\"\n    batch_ndims = 1\n    batch_shapes = {\n        sample.shape[:batch_ndims] for sample in posterior_sample.values()\n    }\n    if len(batch_shapes) &gt; 1:\n        msg = f\"Inconsistent batch shapes found in posterior_sample: {batch_shapes}\"\n        raise ValueError(msg)\n    (self.num_samples,) = batch_shapes.pop()\n    self.posterior = posterior_sample\n    self._return_sites = return_sites or (self.param_output,)\n    self._is_fitted = True\n    self._dt_posterior = _dict_to_datatree(self.posterior)\n\n    return self\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.predict_on_batch","title":"predict_on_batch","text":"<pre><code>predict_on_batch(X: ArrayLike, *, intervention: dict | None = None, rng_key: Array | None = None, in_sample: bool = True, return_sites: tuple[str] | None = None, **kwargs: object) -&gt; DataTree\n</code></pre> <p>Predict the output based on the fitted model.</p> <p>This method returns predictions for a single batch of input data and is better suited for:     1) Models incompatible with <code>.predict()</code> due to their posterior sample         shapes.     2) Scenarios where writing results to to files (e.g., disk, cloud storage)         is not desired.     3) Smaller datasets, as this method may be slower due to limited         parallelism.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input data with shape <code>(n_samples_X, n_features)</code>.</p> required <code>intervention</code> <code>dict | None</code> <p>A dictionary mapping sample sites to their corresponding intervention values. Interventions enable counterfactual analysis by modifying the specified sample sites during prediction (posterior predictive sampling).</p> <code>None</code> <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed.</p> <code>None</code> <code>in_sample</code> <code>bool</code> <p>Specifies the group where posterior predictive samples are stored in the returned output. If <code>True</code>, samples are stored in the <code>posterior_predictive</code> group, indicating they were generated based on data used during model fitting. If <code>False</code>, samples are stored in the <code>predictions</code> group, indicating they were generated based on out-of-sample data.</p> <code>True</code> <code>return_sites</code> <code>tuple[str] | None</code> <p>Names of variables (sites) to return. If <code>None</code>, samples <code>self.param_output</code> and deterministic sites.</p> <code>None</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataTree</code> <p>Posterior predictive samples. Posterior samples are included if available.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>self.param_output</code> is passed as an argument.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def predict_on_batch(\n    self,\n    X: ArrayLike,\n    *,\n    intervention: dict | None = None,\n    rng_key: Array | None = None,\n    in_sample: bool = True,\n    return_sites: tuple[str] | None = None,\n    **kwargs: object,\n) -&gt; xr.DataTree:\n    \"\"\"Predict the output based on the fitted model.\n\n    This method returns predictions for a single batch of input data and is better\n    suited for:\n        1) Models incompatible with `.predict()` due to their posterior sample\n            shapes.\n        2) Scenarios where writing results to to files (e.g., disk, cloud storage)\n            is not desired.\n        3) Smaller datasets, as this method may be slower due to limited\n            parallelism.\n\n    Args:\n        X (ArrayLike): Input data with shape `(n_samples_X, n_features)`.\n        intervention (dict | None, optional): A dictionary mapping sample sites to\n            their corresponding intervention values. Interventions enable\n            counterfactual analysis by modifying the specified sample sites during\n            prediction (posterior predictive sampling).\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed.\n        in_sample (bool, optional): Specifies the group where posterior predictive\n            samples are stored in the returned output. If `True`, samples are stored\n            in the `posterior_predictive` group, indicating they were generated\n            based on data used during model fitting. If `False`, samples are stored\n            in the `predictions` group, indicating they were generated based on\n            out-of-sample data.\n        return_sites (tuple[str] | None, optional): Names of variables (sites) to\n            return. If `None`, samples `self.param_output` and deterministic sites.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        Posterior predictive samples. Posterior samples are included if available.\n\n    Raises:\n        TypeError: If `self.param_output` is passed as an argument.\n    \"\"\"\n    _check_is_fitted(self)\n\n    if rng_key is None:\n        self.rng_key, rng_key = random.split(self.rng_key)\n\n    X = jnp.asarray(check_array(X))\n\n    # Validate the provided parameters against the kernel's signature\n    args_bound = (\n        signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n    )\n    if self.param_output in args_bound:\n        sub = self.param_output\n        msg = f\"{sub!r} is not allowed in `.predict_on_batch()`.\"\n        raise TypeError(msg)\n\n    if intervention is None:\n        kernel = self.kernel\n    else:\n        rng_key, rng_subkey = random.split(rng_key)\n        kernel = seed(do(self.kernel, data=intervention), rng_seed=rng_subkey)\n\n    out = xr.DataTree(name=\"root\")\n    out[\"posterior\"] = self._dt_posterior\n    out[\"posterior_predictive\" if in_sample else \"predictions\"] = _dict_to_datatree(\n        _sample_forward(\n            kernel,\n            rng_key=rng_key,\n            num_samples=self.num_samples,\n            return_sites=return_sites or self._return_sites,\n            posterior_samples=self.posterior,\n            model_kwargs=args_bound,\n        ),\n    )\n\n    return out\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.predict","title":"predict","text":"<pre><code>predict(X: ArrayLike | ArrayLoader, *, intervention: dict | None = None, rng_key: Array | None = None, in_sample: bool = True, return_sites: tuple[str] | None = None, batch_size: int | None = None, output_dir: str | Path | None = None, progress: bool = True, **kwargs: object) -&gt; DataTree\n</code></pre> <p>Predict the output based on the fitted model.</p> <p>This method performs posterior predictive sampling to generate model-based predictions. It is optimized for batch processing of large input data and is not recommended for use in loops that process only a few inputs at a time. Results are written to disk in the Zarr format, with sampling and file writing decoupled and executed concurrently.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike | ArrayLoader</code> <p>Input data, either an array-like of shape <code>(n_samples, n_features)</code> or a data loader that holds all array-like objects and handles batching internally; if a data loader is passed, <code>batch_size</code> is ignored.</p> required <code>intervention</code> <code>dict | None</code> <p>A dictionary mapping sample sites to their corresponding intervention values. Interventions enable counterfactual analysis by modifying the specified sample sites during prediction (posterior predictive sampling).</p> <code>None</code> <code>rng_key</code> <code>Array | None</code> <p>A pseudo-random number generator key. By default, an internal key is used and split as needed.</p> <code>None</code> <code>in_sample</code> <code>bool</code> <p>Specifies the group where posterior predictive samples are stored in the returned output. If <code>True</code>, samples are stored in the <code>posterior_predictive</code> group, indicating they were generated based on data used during model fitting. If <code>False</code>, samples are stored in the <code>predictions</code> group, indicating they were generated based on out-of-sample data.</p> <code>True</code> <code>return_sites</code> <code>tuple[str] | None</code> <p>Names of variables (sites) to return. If <code>None</code>, samples <code>self.param_output</code> and deterministic sites.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>The size of batches for data loading during posterior predictive sampling. By default, it is set to the total number of samples (<code>n_samples_X</code>). This value also determines the chunk size for storing the posterior predictive samples.</p> <code>None</code> <code>output_dir</code> <code>str | Path | None</code> <p>The directory where the outputs will be saved. If the specified directory does not exist, it will be created automatically. If <code>None</code>, a default temporary directory will be created. A timestamped subdirectory will be generated within this directory to store the outputs. Outputs are saved in the Zarr format.</p> <code>None</code> <code>progress</code> <code>bool</code> <p>Whether to display a progress bar.</p> <code>True</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataTree</code> <p>Posterior predictive samples. Posterior samples are included if available.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>self.param_output</code> is passed as an argument.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def predict(\n    self,\n    X: ArrayLike | ArrayLoader,\n    *,\n    intervention: dict | None = None,\n    rng_key: Array | None = None,\n    in_sample: bool = True,\n    return_sites: tuple[str] | None = None,\n    batch_size: int | None = None,\n    output_dir: str | Path | None = None,\n    progress: bool = True,\n    **kwargs: object,\n) -&gt; xr.DataTree:\n    \"\"\"Predict the output based on the fitted model.\n\n    This method performs posterior predictive sampling to generate model-based\n    predictions. It is optimized for batch processing of large input data and is not\n    recommended for use in loops that process only a few inputs at a time. Results\n    are written to disk in the Zarr format, with sampling and file writing decoupled\n    and executed concurrently.\n\n    Args:\n        X (ArrayLike | ArrayLoader): Input data, either an array-like of shape\n            `(n_samples, n_features)` or a data loader that holds all array-like\n            objects and handles batching internally; if a data loader is passed,\n            `batch_size` is ignored.\n        intervention (dict | None, optional): A dictionary mapping sample sites to\n            their corresponding intervention values. Interventions enable\n            counterfactual analysis by modifying the specified sample sites during\n            prediction (posterior predictive sampling).\n        rng_key (Array | None, optional): A pseudo-random number generator key. By\n            default, an internal key is used and split as needed.\n        in_sample (bool, optional): Specifies the group where posterior predictive\n            samples are stored in the returned output. If `True`, samples are stored\n            in the `posterior_predictive` group, indicating they were generated\n            based on data used during model fitting. If `False`, samples are stored\n            in the `predictions` group, indicating they were generated based on\n            out-of-sample data.\n        return_sites (tuple[str] | None, optional): Names of variables (sites) to\n            return. If `None`, samples `self.param_output` and deterministic sites.\n        batch_size (int | None, optional): The size of batches for data loading\n            during posterior predictive sampling. By default, it is set to the\n            total number of samples (`n_samples_X`). This value also determines the\n            chunk size for storing the posterior predictive samples.\n        output_dir (str | Path | None, optional): The directory where the outputs\n            will be saved. If the specified directory does not exist, it will be\n            created automatically. If `None`, a default temporary directory will be\n            created. A timestamped subdirectory will be generated within this\n            directory to store the outputs. Outputs are saved in the Zarr format.\n        progress (bool, optional): Whether to display a progress bar.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        Posterior predictive samples. Posterior samples are included if available.\n\n    Raises:\n        TypeError: If `self.param_output` is passed as an argument.\n    \"\"\"\n    _check_is_fitted(self)\n\n    # Check for compatibility with the `.predict()` method.\n    #\n    # If any array in the posterior has shape (num_samples, num_obs)\u2014i.e.,\n    # `ndim == 2` and the second dimension matches the number of observations in\n    # `X`\u2014it suggests that the model produces per-observation posterior samples.\n    # This makes it incompatible with the current `.predict()` implementation, which\n    # uses sharded parallelism. In such cases, fall back to `.predict_on_batch()`\n    # and raise a warning.\n    if isinstance(X, ArrayLike):\n        ndim_posterior_sample = 2\n        if self.posterior and any(\n            v.ndim == ndim_posterior_sample and v.shape[1] == len(X)\n            for v in self.posterior.values()\n        ):\n            msg = (\n                \"One or more posterior sample shapes are not compatible with \"\n                \"`.predict()` under sharded parallelism; falling back to \"\n                \"`.predict_on_batch()`.\"\n            )\n            warn(msg, category=UserWarning, stacklevel=2)\n\n            return self.predict_on_batch(\n                X,\n                intervention=intervention,\n                rng_key=rng_key,\n                in_sample=in_sample,\n                return_sites=return_sites or self._return_sites,\n                **kwargs,\n            )\n        # Validate the provided parameters against the kernel's signature\n        args_bound = (\n            signature(self.kernel).bind(**{self.param_input: X, **kwargs}).arguments\n        )\n        if self.param_output in args_bound:\n            sub = self.param_output\n            msg = f\"{sub!r} is not allowed in `.predict()`.\"\n            raise TypeError(msg)\n\n    if rng_key is None:\n        self.rng_key, rng_key = random.split(self.rng_key)\n\n    if intervention is None:\n        kernel = self.kernel\n    else:\n        rng_key, rng_subkey = random.split(rng_key)\n        kernel = seed(do(self.kernel, data=intervention), rng_seed=rng_subkey)\n\n    kwargs_array, kwargs_extra = _group_kwargs(kwargs)\n    if self._fn_sample_posterior_predictive is None:\n        self._fn_sample_posterior_predictive = _create_sharded_sampler(\n            self._mesh,\n            len(kwargs_array),\n            len(kwargs_extra),\n        )\n\n    if output_dir is None:\n        if not hasattr(self, \"temp_dir\"):\n            self.temp_dir = TemporaryDirectory()\n            logger.info(\n                \"Temporary directory created at: %s\",\n                self.temp_dir.name,\n            )\n        output_dir = self.temp_dir.name\n        logger.info(\n            \"No output directory provided. Using the model's temporary directory \"\n            \"for storing output.\",\n        )\n    output_subdir = _create_output_subdir(output_dir)\n\n    return self.__sample_posterior_predictive(\n        fn_sample_posterior_predictive=self._fn_sample_posterior_predictive,\n        kernel=kernel,\n        X=X,\n        rng_key=rng_key,\n        group=\"posterior_predictive\" if in_sample else \"predictions\",\n        return_sites=return_sites or self._return_sites,\n        batch_size=batch_size,\n        output_dir=output_subdir,\n        progress=progress,\n        **kwargs,\n    )\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.estimate_effect","title":"estimate_effect","text":"<pre><code>estimate_effect(output_baseline: DataTree | None = None, output_intervention: DataTree | None = None, args_baseline: dict | None = None, args_intervention: dict | None = None) -&gt; DataTree\n</code></pre> <p>Estimate the effect of an intervention.</p> <p>Parameters:</p> Name Type Description Default <code>output_baseline</code> <code>DataTree | None</code> <p>Precomputed output for the baseline scenario.</p> <code>None</code> <code>output_intervention</code> <code>DataTree | None</code> <p>Precomputed output for the intervention scenario.</p> <code>None</code> <code>args_baseline</code> <code>dict | None</code> <p>Input arguments for the baseline scenario. Passed to the <code>.predict()</code> method to compute predictions if <code>output_baseline</code> is not provided. Ignored if <code>output_baseline</code> is already given.</p> <code>None</code> <code>args_intervention</code> <code>dict | None</code> <p>Input arguments for the intervention scenario. Passed to the <code>.predict()</code> method to compute predictions if <code>output_intervention</code> is not provided. Ignored if <code>output_intervention</code> is already given.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataTree</code> <p>The estimated impact of an intervention.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>output_baseline</code> nor <code>args_baseline</code> is provided, or if neither <code>output_intervention</code> nor <code>args_intervention</code> is provided.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def estimate_effect(\n    self,\n    output_baseline: xr.DataTree | None = None,\n    output_intervention: xr.DataTree | None = None,\n    args_baseline: dict | None = None,\n    args_intervention: dict | None = None,\n) -&gt; xr.DataTree:\n    \"\"\"Estimate the effect of an intervention.\n\n    Args:\n        output_baseline (xr.DataTree | None, optional): Precomputed output for the\n            baseline scenario.\n        output_intervention (xr.DataTree | None, optional): Precomputed output for\n            the intervention scenario.\n        args_baseline (dict | None, optional): Input arguments for the baseline\n            scenario. Passed to the `.predict()` method to compute predictions if\n            `output_baseline` is not provided. Ignored if `output_baseline` is\n            already given.\n        args_intervention (dict | None, optional): Input arguments for the\n            intervention scenario. Passed to the `.predict()` method to compute\n            predictions if `output_intervention` is not provided. Ignored if\n            `output_intervention` is already given.\n\n    Returns:\n        The estimated impact of an intervention.\n\n    Raises:\n        ValueError: If neither `output_baseline` nor `args_baseline` is provided, or\n            if neither `output_intervention` nor `args_intervention` is provided.\n    \"\"\"\n    _check_is_fitted(self)\n\n    if output_baseline:\n        dt_baseline = output_baseline\n    elif args_baseline:\n        dt_baseline = self.predict(**args_baseline)\n    else:\n        msg = \"Either `output_baseline` or `args_baseline` must be provided.\"\n        raise ValueError(msg)\n\n    if output_intervention:\n        dt_intervention = output_intervention\n    elif args_intervention:\n        dt_intervention = self.predict(**args_intervention)\n    else:\n        msg = (\n            \"Either `output_intervention` or `args_intervention` must be provided.\"\n        )\n        raise ValueError(msg)\n\n    group = _validate_group(dt_baseline, dt_intervention)\n\n    out = xr.DataTree(name=\"root\")\n    out[group] = dt_intervention[group] - dt_baseline[group]\n\n    return out\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.log_likelihood","title":"log_likelihood","text":"<pre><code>log_likelihood(X: ArrayLike | ArrayLoader, y: ArrayLike | None = None, *, batch_size: int | None = None, output_dir: str | Path | None = None, progress: bool = True, **kwargs: object) -&gt; DataTree\n</code></pre> <p>Compute the log likelihood of the data under the given model.</p> <p>Results are written to disk in the Zarr format, with computing and file writing decoupled and executed concurrently.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike | ArrayLoader</code> <p>Input data, either an array-like of shape <code>(n_samples, n_features)</code> or a data loader that holds all array-like objects and handles batching internally; if a data loader is passed, <code>batch_size</code> is ignored.</p> required <code>y</code> <code>ArrayLike | None</code> <p>Output data with shape <code>(n_samples_Y,)</code>. Must be <code>None</code> if <code>X</code> is a data loader.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>The size of batches for data loading during posterior predictive sampling. By default, it is set to the total number of samples (<code>n_samples_X</code>). This value also determines the chunk size for storing the log-likelihood values.</p> <code>None</code> <code>output_dir</code> <code>str | Path | None</code> <p>The directory where the outputs will be saved. If the specified directory does not exist, it will be created automatically. If <code>None</code>, a default temporary directory will be created. A timestamped subdirectory will be generated within this directory to store the outputs. Outputs are saved in the Zarr format.</p> <code>None</code> <code>progress</code> <code>bool</code> <p>Whether to display a progress bar.</p> <code>True</code> <code>**kwargs</code> <code>object</code> <p>Additional arguments passed to the model. All array-like values are expected to be JAX arrays.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataTree</code> <p>Log-likelihood values. Posterior samples are included if available.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def log_likelihood(\n    self,\n    X: ArrayLike | ArrayLoader,\n    y: ArrayLike | None = None,\n    *,\n    batch_size: int | None = None,\n    output_dir: str | Path | None = None,\n    progress: bool = True,\n    **kwargs: object,\n) -&gt; xr.DataTree:\n    \"\"\"Compute the log likelihood of the data under the given model.\n\n    Results are written to disk in the Zarr format, with computing and file writing\n    decoupled and executed concurrently.\n\n    Args:\n        X (ArrayLike | ArrayLoader): Input data, either an array-like of shape\n            `(n_samples, n_features)` or a data loader that holds all array-like\n            objects and handles batching internally; if a data loader is passed,\n            `batch_size` is ignored.\n        y (ArrayLike | None): Output data with shape `(n_samples_Y,)`. Must be\n            `None` if `X` is a data loader.\n        batch_size (int | None, optional): The size of batches for data loading\n            during posterior predictive sampling. By default, it is set to the total\n            number of samples (`n_samples_X`). This value also determines the chunk\n            size for storing the log-likelihood values.\n        output_dir (str | Path | None, optional): The directory where the outputs\n            will be saved. If the specified directory does not exist, it will be\n            created automatically. If `None`, a default temporary directory will be\n            created. A timestamped subdirectory will be generated within this\n            directory to store the outputs. Outputs are saved in the Zarr format.\n        progress (bool, optional): Whether to display a progress bar.\n        **kwargs (object): Additional arguments passed to the model. All array-like\n            values are expected to be JAX arrays.\n\n    Returns:\n        Log-likelihood values. Posterior samples are included if available.\n    \"\"\"\n    _check_is_fitted(self)\n\n    kwargs_array, kwargs_extra = _group_kwargs(kwargs)\n    if self._fn_log_likelihood is None:\n        self._fn_log_likelihood = _create_sharded_log_likelihood(\n            self._mesh,\n            len(kwargs_array),\n            len(kwargs_extra),\n        )\n\n    if output_dir is None:\n        if not hasattr(self, \"temp_dir\"):\n            self.temp_dir = TemporaryDirectory()\n            logger.info(\n                \"Temporary directory created at: %s\",\n                self.temp_dir.name,\n            )\n        output_dir = self.temp_dir.name\n        logger.info(\n            \"No output directory provided. Using the model's temporary directory \"\n            \"for storing output.\",\n        )\n    output_subdir = _create_output_subdir(output_dir)\n\n    dataloader, _ = _setup_inputs(\n        X=X,\n        y=y,\n        rng_key=self.rng_key,\n        batch_size=batch_size,\n        shuffle=False,\n        device=self._device,\n        **kwargs,\n    )\n\n    site = self.param_output\n    pbar = tqdm(\n        desc=(f\"Computing log-likelihood of {site}...\"),\n        total=len(dataloader),\n        disable=not progress,\n    )\n\n    zarr_group = open_group(output_subdir, mode=\"w\")\n    zarr_arr = {}\n    threads, queues, error_queue = _start_writer_threads(\n        (site,),\n        group_path=output_subdir,\n        writer=_writer,\n        queue_size=min(cpu_count() or 1, 4),\n    )\n    try:\n        for batch, n_pad in dataloader:\n            kwargs_batch = [\n                v\n                for k, v in batch.items()\n                if k not in (self.param_input, self.param_output)\n            ]\n            arr = device_get(\n                self._fn_log_likelihood(\n                    # Although computing the log-likelihood is deterministic, the\n                    # model still needs to be seeded in order to trace its graph.\n                    seed(self.kernel, rng_seed=self.rng_key),\n                    self.posterior,\n                    self.param_input,\n                    site,\n                    kwargs_array._fields + kwargs_extra._fields,\n                    batch[self.param_input],\n                    batch[self.param_output],\n                    *(*kwargs_batch, *kwargs_extra),\n                ),\n            )\n            if site not in zarr_arr:\n                zarr_arr[site] = zarr_group.create_array(\n                    name=site,\n                    shape=(self.num_samples, 0, *arr.shape[2:]),\n                    dtype=\"float32\" if arr.dtype == \"bfloat16\" else arr.dtype,\n                    chunks=(\n                        self.num_samples,\n                        dataloader.batch_size,\n                        *arr.shape[2:],\n                    ),\n                    dimension_names=(\n                        \"draw\",\n                        *tuple(f\"{site}_dim_{i}\" for i in range(arr.ndim - 1)),\n                    ),\n                )\n            queues[site].put(arr[:, : -n_pad or None])\n            if not error_queue.empty():\n                _, exc, tb = error_queue.get()\n                raise exc.with_traceback(tb)\n            pbar.update()\n        pbar.set_description(\"Computation complete, writing in progress...\")\n        _shutdown_writer_threads(threads, queues=queues)\n    except:\n        _shutdown_writer_threads(threads, queues=queues)\n        logger.exception(\n            \"Exception encountered. Cleaning up output directory: %s\",\n            output_subdir,\n        )\n        rmtree(output_subdir, ignore_errors=True)\n        raise\n    finally:\n        pbar.close()\n\n    ds = open_zarr(output_subdir, consolidated=False).expand_dims(\n        dim=\"chain\",\n        axis=0,\n    )\n    ds = ds.assign_coords(\n        {k: np.arange(ds.sizes[k]) for k in ds.sizes},\n    ).assign_attrs(_make_attrs())\n    out = xr.DataTree(name=\"root\")\n    out[\"posterior\"] = self._dt_posterior\n    out[\"log_likelihood\"] = xr.DataTree(ds)\n\n    return out\n</code></pre>"},{"location":"impact_model/#aimz.model.impact_model.ImpactModel.cleanup","title":"cleanup","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Clean up the temporary directory created for storing outputs.</p> <p>If the temporary directory was never created or has already been cleaned up, this method does nothing. It does not delete any explicitly specified output directory. While the temporary directory is typically removed automatically during garbage collection, this behavior is not guaranteed. Therefore, calling this method explicitly is recommended to ensure timely resource release.</p> Source code in <code>aimz/model/impact_model.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Clean up the temporary directory created for storing outputs.\n\n    If the temporary directory was never created or has already been cleaned up,\n    this method does nothing. It does not delete any explicitly specified output\n    directory. While the temporary directory is typically removed automatically\n    during garbage collection, this behavior is not guaranteed. Therefore, calling\n    this method explicitly is recommended to ensure timely resource release.\n    \"\"\"\n    if hasattr(self, \"temp_dir\"):\n        logger.info(\"Temporary directory cleaned up at: %s\", self.temp_dir.name)\n        self.temp_dir.cleanup()\n        del self.temp_dir\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>aimz requires Python 3.11 or higher. It is available via PyPI and conda-forge.</p>"},{"location":"installation/#install-with-pip","title":"Install with pip","text":"<p>CPU (default):</p> <pre><code>pip install -U aimz\n</code></pre> <p>GPU (NVIDIA, CUDA 12):</p> <pre><code>pip install -U \"aimz[gpu]\"\n</code></pre> <p>Warning</p> <p>GPU support is not available on Windows due to dependence on JAX. For GPU acceleration, use Linux or WSL2 with a compatible NVIDIA GPU and CUDA drivers.</p>"},{"location":"installation/#install-with-conda","title":"Install with conda","text":"<pre><code>conda install conda-forge::aimz\n</code></pre>"},{"location":"installation/#install-from-github","title":"Install from GitHub","text":"<pre><code># Latest commit from the main branch (CPU version)\npip install aimz@git+https://github.com/markean/aimz.git\n\n# Specific release tag (replace &lt;release_tag&gt; with the desired tag)\npip install aimz@git+https://github.com/markean/aimz.git@&lt;release_tag&gt;\n\n# GPU-enabled version from the main branch\npip install aimz[gpu]@git+https://github.com/markean/aimz.git\n</code></pre>"},{"location":"model_persistence/","title":"Model Persistence","text":"<p>Model persistence allows you to save a trained model to disk and reload it later for inference or continued training. This documentation shows how to serialize and deserialize an <code>ImpactModel</code> instance using the <code>dill</code> package. <code>dill</code> can handle a wider range of Python objects than the standard <code>pickle</code> module, including closures and local functions, making it convenient to use and reducing boilerplate code.</p>"},{"location":"model_persistence/#model-training","title":"Model Training","text":"<pre><code>from pathlib import Path\n\nimport dill\nimport jax.numpy as jnp\nimport numpyro.distributions as dist\nfrom jax import random\nfrom jax.typing import ArrayLike\nfrom numpyro import optim, sample\nfrom numpyro.infer import SVI, Trace_ELBO\nfrom numpyro.infer.autoguide import AutoNormal\n\nfrom aimz.model import ImpactModel\n\n\ndef model(X: ArrayLike, y: ArrayLike | None = None) -&gt; None:\n    \"\"\"Linear regression model.\"\"\"\n    w = sample(\"w\", dist.Normal().expand((X.shape[1],)))\n    b = sample(\"b\", dist.Normal())\n    mu = jnp.dot(X, w) + b\n    sigma = sample(\"sigma\", dist.Exponential())\n    sample(\"y\", dist.Normal(mu, sigma), obs=y)\n\n\nrng_key = random.key(42)\nrng_key, rng_key_w, rng_key_b, rng_key_x, rng_key_e = random.split(rng_key, 5)\nw = random.normal(rng_key_w, (10,))\nb = random.normal(rng_key_b)\nX = random.normal(rng_key_x, (1000, 10))\ne = random.normal(rng_key_e, (1000,))\ny = jnp.dot(X, w) + b + e\n\nrng_key, rng_subkey = random.split(rng_key)\nim = ImpactModel(\n    model,\n    rng_key=rng_subkey,\n    inference=SVI(\n        model,\n        guide=AutoNormal(model),\n        optim=optim.Adam(step_size=1e-3),\n        loss=Trace_ELBO(),\n    ),\n)\nim.fit_on_batch(X, y)\n</code></pre>"},{"location":"model_persistence/#serialization","title":"Serialization","text":"<p>Save a trained <code>ImpactModel</code> (and optionally its input data) to disk for later use:</p> <pre><code>with Path.open(\"train.dill\", \"wb\") as f:\n    dill.dump((im, X, y), f)\n</code></pre>"},{"location":"model_persistence/#deserialization","title":"Deserialization","text":"<p>Load a previously saved <code>ImpactModel</code> (and optionally its input data) from disk in a fresh new session or different runtime environment. To use the loaded model correctly, the same dependencies, imports, and any constants or variables that the <code>model</code> relied on when it was saved must be available. Any JAX array\u2014whether part of the <code>ImpactModel</code> or the input data\u2014will be placed on the default device.</p> <pre><code>from pathlib import Path\n\nimport dill\nimport jax.numpy as jnp\nimport numpyro.distributions as dist\nfrom numpyro import sample\n\nwith Path.open(\"train.dill\", \"rb\") as f:\n    im, X, y = dill.load(f)\n</code></pre>"},{"location":"model_persistence/#model-usage","title":"Model Usage","text":"<pre><code># Resume training from the previous SVI state\nim.fit_on_batch(X, y)\n\n# Predict using the loaded model\nim.predict_on_batch(X)\n</code></pre>"},{"location":"model_persistence/#resources","title":"Resources","text":"<ul> <li><code>dill</code> documentation</li> <li><code>jax</code> <code>Array</code> serialization</li> </ul>"},{"location":"wip/","title":"WIP","text":""}]}